import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_curve, auc, precision_recall_curve
from sklearn.model_selection import learning_curve
from imblearn.over_sampling import SMOTE
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import optuna
import joblib
import os

# í°íŠ¸ì§€ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False
pd.options.display.float_format = '{:.2f}'.format

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë‡Œì¡¸ì¤‘ ì˜ˆì¸¡ ë¶„ì„ ì‹œìŠ¤í…œ",
    page_icon="ğŸ¥",
    layout="wide"
)

# ì œëª©
st.title("ğŸ¥ ë‡Œì¡¸ì¤‘ ì˜ˆì¸¡ ë¶„ì„ ì‹œìŠ¤í…œ")
st.write("ë‡Œì¡¸ì¤‘ ìœ„í—˜ ìš”ì¸ì„ ë¶„ì„í•˜ê³  ì˜ˆì¸¡ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.")

# ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
@st.cache_data
def load_data():
    try:
        df = pd.read_csv("../dataset/healthcare-dataset-stroke-data.csv", encoding='utf-8')
        return df
    except FileNotFoundError:
        st.error("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. '../dataset/healthcare-dataset-stroke-data.csv' íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return None

# ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_data(df):
    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    df['bmi'].fillna(df['bmi'].median(), inplace=True)
    df = df[df['gender'] != 'Other'].drop(columns='id')
    
    return df

# ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜
@st.cache_data
def train_model(df):
    # íŠ¹ì„± ë¶„ë¥˜
    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
    categorical_features = df.select_dtypes(include=['object', 'category']).columns.tolist()
    numeric_features.remove('stroke')
    
    # ë°ì´í„° ë¶„í• 
    X = df.drop("stroke", axis=1)
    y = df["stroke"]
    
    # ì „ì²˜ë¦¬ êµ¬ì„±
    categorical_transformer = Pipeline(steps=[
        ("onehot", OneHotEncoder(handle_unknown="ignore"))
    ])
    
    preprocessor = ColumnTransformer(
        transformers=[
            ("num", "passthrough", numeric_features),
            ("cat", categorical_transformer, categorical_features),
        ],
        remainder="passthrough"
    )
    
    # í•™ìŠµ/ë°ì´í„° ë¶„ë¦¬
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, stratify=y, test_size=0.2, random_state=42
    )
    
    # ì „ì²˜ë¦¬ ì‹¤í–‰
    X_train_preprocessed = preprocessor.fit_transform(X_train)
    X_test_preprocessed = preprocessor.transform(X_test)
    
    # SMOTEë¥¼ ì‚¬ìš©í•œ ìµœì í™”ëœ ë°ì´í„°ì…‹ ìƒì„±
    X_train_resampled, y_train_resampled, _ = create_optimized_dataset(
        X_train, y_train, X_test, y_test, preprocessor
    )
    
    # ëª¨ë¸ í•™ìŠµ
    model = RandomForestClassifier(random_state=42)
    model.fit(X_train_resampled, y_train_resampled)
    
    # ì˜ˆì¸¡ ë° í‰ê°€
    y_pred = model.predict(X_test_preprocessed)
    
    # íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚°
    categorical_feature_names = []
    for i, col in enumerate(categorical_features):
        categories = preprocessor.named_transformers_['cat'].named_steps['onehot'].categories_[i]
        categorical_feature_names.extend([f"{col}_{cat}" for cat in categories])
    
    all_feature_names = numeric_features + categorical_feature_names
    
    feature_importance = pd.DataFrame({
        'feature': all_feature_names,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    return model, preprocessor, X_test, y_test, y_pred, feature_importance

# Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” í•¨ìˆ˜
def optimize_hyperparameters(X_train, y_train, X_test, y_test, preprocessor):
    def objective(trial):
        n_estimators = trial.suggest_int('n_estimators', 50, 300)
        max_depth = trial.suggest_int('max_depth', 3, 20)
        min_samples_split = trial.suggest_int('min_samples_split', 2, 20)
        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)
        
        model = RandomForestClassifier(
            n_estimators=n_estimators, max_depth=max_depth,
            min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf,
            random_state=42
        )
        
        # SMOTEë¥¼ ì‚¬ìš©í•œ ìµœì í™”ëœ ë°ì´í„°ì…‹ ìƒì„±
        X_train_resampled, y_train_resampled, X_test_preprocessed = create_optimized_dataset(
            X_train, y_train, X_test, y_test, preprocessor
        )
        
        model.fit(X_train_resampled, y_train_resampled)
        y_pred = model.predict(X_test_preprocessed)
        
        return f1_score(y_test, y_pred, average='weighted')
    
    study = optuna.create_study(direction='maximize')
    study.optimize(objective, n_trials=20)
    return study.best_params, study.best_value, study

# í†µê³„ ì§€í‘œ ê³„ì‚° í•¨ìˆ˜
def calculate_statistics(y_true, y_pred, y_pred_proba):
    """ì¶”ê°€ í†µê³„ ì§€í‘œ ê³„ì‚°"""
    from sklearn.metrics import matthews_corrcoef, cohen_kappa_score, balanced_accuracy_score
    
    # Matthews Correlation Coefficient
    mcc = matthews_corrcoef(y_true, y_pred)
    
    # Cohen's Kappa
    kappa = cohen_kappa_score(y_true, y_pred)
    
    # Balanced Accuracy
    bal_acc = balanced_accuracy_score(y_true, y_pred)
    
    return mcc, kappa, bal_acc

# í•™ìŠµ ê³¡ì„  ê³„ì‚° í•¨ìˆ˜
def plot_learning_curve(model, X, y, title="í•™ìŠµ ê³¡ì„ "):
    """í•™ìŠµ ê³¡ì„  ê³„ì‚° ë° ì‹œê°í™”"""
    train_sizes, train_scores, val_scores = learning_curve(
        model, X, y, cv=5, n_jobs=-1, 
        train_sizes=np.linspace(0.1, 1.0, 10),
        scoring='f1_weighted'
    )
    
    train_mean = np.mean(train_scores, axis=1)
    train_std = np.std(train_scores, axis=1)
    val_mean = np.mean(val_scores, axis=1)
    val_std = np.std(val_scores, axis=1)
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=train_sizes, y=train_mean,
        mode='lines+markers',
        name='í›ˆë ¨ ì ìˆ˜',
        line=dict(color='blue'),
        error_y=dict(type='data', array=train_std, visible=True)
    ))
    
    fig.add_trace(go.Scatter(
        x=train_sizes, y=val_mean,
        mode='lines+markers',
        name='ê²€ì¦ ì ìˆ˜',
        line=dict(color='red'),
        error_y=dict(type='data', array=val_std, visible=True)
    ))
    
    fig.update_layout(
        title=title,
        xaxis_title='í›ˆë ¨ ìƒ˜í”Œ ìˆ˜',
        yaxis_title='F1 Score',
        legend=dict(x=0.02, y=0.98)
    )
    
    return fig

# ROC ì»¤ë¸Œ ê³„ì‚° í•¨ìˆ˜
def plot_roc_curve(y_true, y_pred_proba, title="ROC ì»¤ë¸Œ"):
    """ROC ì»¤ë¸Œ ê³„ì‚° ë° ì‹œê°í™”"""
    fpr, tpr, _ = roc_curve(y_true, y_pred_proba[:, 1])
    roc_auc = auc(fpr, tpr)
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=fpr, y=tpr,
        mode='lines',
        name=f'ROC ì»¤ë¸Œ (AUC = {roc_auc:.3f})',
        line=dict(color='blue', width=2)
    ))
    
    fig.add_trace(go.Scatter(
        x=[0, 1], y=[0, 1],
        mode='lines',
        name='ë¬´ì‘ìœ„ ë¶„ë¥˜ê¸°',
        line=dict(color='red', width=2, dash='dash')
    ))
    
    fig.update_layout(
        title=title,
        xaxis_title='False Positive Rate',
        yaxis_title='True Positive Rate',
        xaxis=dict(range=[0, 1]),
        yaxis=dict(range=[0, 1])
    )
    
    return fig, roc_auc

# ìƒê´€ê´€ê³„ Heatmap ê³„ì‚° í•¨ìˆ˜
def plot_correlation_heatmap(df, title="ìƒê´€ê´€ê³„ Heatmap"):
    """ìƒê´€ê´€ê³„ Heatmap ê³„ì‚° ë° ì‹œê°í™”"""
    # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë§Œ ì„ íƒ
    numeric_df = df.select_dtypes(include=['int64', 'float64'])
    
    # ìƒê´€ê´€ê³„ ê³„ì‚°
    correlation_matrix = numeric_df.corr()
    reversed_y = correlation_matrix.columns[::-1]
    reversed_z = correlation_matrix.values[::-1]

    # Heatmap ìƒì„±
    fig = go.Figure(data=go.Heatmap(
        z=reversed_z,
        x=correlation_matrix.columns,
        y=reversed_y,
        colorscale=px.colors.diverging.Cool,
        zmid=0,
        text=np.round(reversed_z, 3),
        texttemplate="%{text}",
        textfont={"size": 10},
        hoverongaps=False
    ))
    
    fig.update_layout(
        title=title,
        xaxis_title="ë³€ìˆ˜",
        yaxis_title="ë³€ìˆ˜",
        width=600,
        height=500
    )
    
    return fig

# ìµœì í™”ëœ ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ í•¨ìˆ˜
def train_and_save_optimized_model(df, best_params):
    # íŠ¹ì„± ë¶„ë¥˜
    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
    categorical_features = df.select_dtypes(include=['object', 'category']).columns.tolist()
    numeric_features.remove('stroke')
    
    # ë°ì´í„° ë¶„í• 
    X = df.drop("stroke", axis=1)
    y = df["stroke"]
    
    # ì „ì²˜ë¦¬ êµ¬ì„±
    categorical_transformer = Pipeline(steps=[
        ("onehot", OneHotEncoder(handle_unknown="ignore"))
    ])
    
    preprocessor = ColumnTransformer(
        transformers=[
            ("num", "passthrough", numeric_features),
            ("cat", categorical_transformer, categorical_features),
        ],
        remainder="passthrough"
    )
    
    # í•™ìŠµ/ë°ì´í„° ë¶„ë¦¬
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, stratify=y, test_size=0.2, random_state=42
    )
    
    # ì „ì²˜ë¦¬ ì‹¤í–‰
    X_train_preprocessed = preprocessor.fit_transform(X_train)
    X_test_preprocessed = preprocessor.transform(X_test)
    
    # SMOTEë¥¼ ì‚¬ìš©í•œ ìµœì í™”ëœ ë°ì´í„°ì…‹ ìƒì„±
    X_train_resampled, y_train_resampled, _ = create_optimized_dataset(
        X_train, y_train, X_test, y_test, preprocessor
    )
    
    # ìµœì í™”ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ í•™ìŠµ
    optimized_model = RandomForestClassifier(
        n_estimators=best_params['n_estimators'],
        max_depth=best_params['max_depth'],
        min_samples_split=best_params['min_samples_split'],
        min_samples_leaf=best_params['min_samples_leaf'],
        random_state=42
    )
    
    optimized_model.fit(X_train_resampled, y_train_resampled)
    
    # ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ê¸° ì €ì¥
    model_data = {
        'model': optimized_model,
        'preprocessor': preprocessor,
        'feature_names': X.columns.tolist(),
        'best_params': best_params
    }
    
    # models ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs('models', exist_ok=True)
    
    # ëª¨ë¸ ì €ì¥
    joblib.dump(model_data, 'models/stroke_prediction_model.pkl')
    
    # ì˜ˆì¸¡ ë° í‰ê°€
    y_pred = optimized_model.predict(X_test_preprocessed)
    
    return optimized_model, preprocessor, X_test, y_test, y_pred, best_params

# ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
def load_saved_model():
    try:
        model_data = joblib.load('models/stroke_prediction_model.pkl')
        return model_data
    except FileNotFoundError:
        return None

# SMOTE ìµœì í™” í•¨ìˆ˜ ì¶”ê°€
def create_optimized_dataset(X_train, y_train, X_test, y_test, preprocessor, smote_params=None):
    """
    SMOTEë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì í™”ëœ ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        X_train, y_train: í›ˆë ¨ ë°ì´í„°
        X_test, y_test: í…ŒìŠ¤íŠ¸ ë°ì´í„°  
        preprocessor: ì „ì²˜ë¦¬ê¸°
        smote_params: SMOTE íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’: random_state=42)
    
    Returns:
        X_train_resampled, y_train_resampled: ë¦¬ìƒ˜í”Œë§ëœ í›ˆë ¨ ë°ì´í„°
        X_test_preprocessed: ì „ì²˜ë¦¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„°
    """
    if smote_params is None:
        smote_params = {'random_state': 42}
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    X_train_preprocessed = preprocessor.transform(X_train)
    X_test_preprocessed = preprocessor.transform(X_test)
    
    # SMOTE ì ìš©
    smote = SMOTE(**smote_params)
    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_preprocessed, y_train)
    
    return X_train_resampled, y_train_resampled, X_test_preprocessed

# SMOTE íŒŒë¼ë¯¸í„° ìµœì í™” í•¨ìˆ˜
def optimize_smote_parameters(X_train, y_train, X_test, y_test, preprocessor):
    """
    SMOTE íŒŒë¼ë¯¸í„°ë¥¼ ìµœì í™”í•˜ëŠ” í•¨ìˆ˜
    
    Returns:
        best_smote_params: ìµœì í™”ëœ SMOTE íŒŒë¼ë¯¸í„°
    """
    def objective(trial):
        # SMOTE íŒŒë¼ë¯¸í„° ì œì•ˆ
        k_neighbors = trial.suggest_int('k_neighbors', 3, 10)
        sampling_strategy = trial.suggest_float('sampling_strategy', 0.5, 1.0)
        
        smote_params = {
            'k_neighbors': k_neighbors,
            'sampling_strategy': sampling_strategy,
            'random_state': 42
        }
        
        # ìµœì í™”ëœ ë°ì´í„°ì…‹ ìƒì„±
        X_train_resampled, y_train_resampled, X_test_preprocessed = create_optimized_dataset(
            X_train, y_train, X_test, y_test, preprocessor, smote_params
        )
        
        # ê°„ë‹¨í•œ ëª¨ë¸ë¡œ í‰ê°€
        model = RandomForestClassifier(n_estimators=50, random_state=42)
        model.fit(X_train_resampled, y_train_resampled)
        y_pred = model.predict(X_test_preprocessed)
        
        return f1_score(y_test, y_pred, average='weighted')
    
    study = optuna.create_study(direction='maximize')
    study.optimize(objective, n_trials=10)
    return study.best_params

# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
def main():
    # ë°ì´í„° ë¡œë“œ
    with st.spinner('ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...'):
        df = load_data()
    
    if df is None:
        return
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    with st.spinner('ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...'):
        df = preprocess_data(df)
    
    # ê¸°ë³¸ ì •ë³´ í‘œì‹œ
    st.subheader("ğŸ“Š ë°ì´í„° ê¸°ë³¸ ì •ë³´")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ì´ ìƒ˜í”Œ ìˆ˜", f"{len(df):,}")
    with col2:
        st.metric("ë‡Œì¡¸ì¤‘ í™˜ì ìˆ˜", f"{df['stroke'].sum():,}")
    with col3:
        st.metric("ë‡Œì¡¸ì¤‘ ë¹„ìœ¨", f"{df['stroke'].mean():.2%}")
    with col4:
        st.metric("íŠ¹ì„± ìˆ˜", f"{len(df.columns)-1}")
    
    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    st.subheader("ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    st.dataframe(df.head(), use_container_width=True)
    
    # ë°ì´í„° ì •ë³´
    with st.expander("ë°ì´í„° ìƒì„¸ ì •ë³´"):
        st.write("**ë°ì´í„° íƒ€ì…:**")
        st.write(df.dtypes)
        
        st.write("**ê¸°ìˆ  í†µê³„:**")
        st.write(df.describe())
        
        st.write("**ê²°ì¸¡ì¹˜ ì •ë³´:**")
        st.write(df.isnull().sum())
    
    # ëª¨ë¸ í•™ìŠµ
    with st.spinner('ëª¨ë¸ í•™ìŠµ ì¤‘...'):
        model, preprocessor, X_test, y_test, y_pred, feature_importance = train_model(df)
        
        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í•  ì •ë³´ ì €ì¥ (í•™ìŠµ ê³¡ì„ ìš©)
        X = df.drop("stroke", axis=1)
        y = df["stroke"]
        X_train, _, y_train, _ = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ (ROC ì»¤ë¸Œìš©)
        X_test_preprocessed = preprocessor.transform(X_test)
    
    # ì €ì¥ëœ ëª¨ë¸ í™•ì¸
    saved_model = load_saved_model()
    
    # Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ë° ëª¨ë¸ ì €ì¥
    optimization_option = st.selectbox(
        "ìµœì í™” ì˜µì…˜ ì„ íƒ",
        ["ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©", "í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”", "SMOTE íŒŒë¼ë¯¸í„° ìµœì í™”", "í•˜ì´í¼íŒŒë¼ë¯¸í„° + SMOTE ìµœì í™”"]
    )
    
    if optimization_option == "í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”":
        with st.spinner('Optunaë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì¤‘...'):
            X_train, X_test_opt, y_train, y_test_opt = train_test_split(
                df.drop("stroke", axis=1), df["stroke"], 
                stratify=df["stroke"], test_size=0.2, random_state=42
            )
            best_params, best_score, study = optimize_hyperparameters(X_train, y_train, X_test_opt, y_test_opt, preprocessor)
    
    elif optimization_option == "SMOTE íŒŒë¼ë¯¸í„° ìµœì í™”":
        with st.spinner('SMOTE íŒŒë¼ë¯¸í„° ìµœì í™” ì¤‘...'):
            X_train, X_test_opt, y_train, y_test_opt = train_test_split(
                df.drop("stroke", axis=1), df["stroke"], 
                stratify=df["stroke"], test_size=0.2, random_state=42
            )
            best_smote_params = optimize_smote_parameters(X_train, y_train, X_test_opt, y_test_opt, preprocessor)
            st.success("SMOTE íŒŒë¼ë¯¸í„° ìµœì í™” ì™„ë£Œ!")
            st.write("**ìµœì  SMOTE íŒŒë¼ë¯¸í„°:**")
            st.json(best_smote_params)
    
    elif optimization_option == "í•˜ì´í¼íŒŒë¼ë¯¸í„° + SMOTE ìµœì í™”":
        with st.spinner('í•˜ì´í¼íŒŒë¼ë¯¸í„°ì™€ SMOTE íŒŒë¼ë¯¸í„° ë™ì‹œ ìµœì í™” ì¤‘...'):
            X_train, X_test_opt, y_train, y_test_opt = train_test_split(
                df.drop("stroke", axis=1), df["stroke"], 
                stratify=df["stroke"], test_size=0.2, random_state=42
            )
            best_params, best_score, study = optimize_hyperparameters(X_train, y_train, X_test_opt, y_test_opt, preprocessor)
            best_smote_params = optimize_smote_parameters(X_train, y_train, X_test_opt, y_test_opt, preprocessor)
            st.success("ëª¨ë“  íŒŒë¼ë¯¸í„° ìµœì í™” ì™„ë£Œ!")
            st.write("**ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:**")
            st.json(best_params)
            st.write("**ìµœì  SMOTE íŒŒë¼ë¯¸í„°:**")
            st.json(best_smote_params)
    
    # ìµœì í™” ê²°ê³¼ í‘œì‹œ ë° ëª¨ë¸ ì €ì¥
    if optimization_option in ["í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”", "í•˜ì´í¼íŒŒë¼ë¯¸í„° + SMOTE ìµœì í™”"]:
        st.success(f"ìµœì í™” ì™„ë£Œ! ìµœê³  F1-Score: {best_score:.4f}")
        st.write("**ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:**")
        st.json(best_params)
        
        # ìµœì í™”ëœ ëª¨ë¸ í•™ìŠµ ë° ì €ì¥
        with st.spinner('ìµœì í™”ëœ ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì¤‘...'):
            optimized_model, optimized_preprocessor, X_test_opt, y_test_opt, y_pred_opt, best_params = train_and_save_optimized_model(df, best_params)
            
            st.success("âœ… ìµœì í™”ëœ ëª¨ë¸ì´ 'models/stroke_prediction_model.pkl'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            # ìµœì í™”ëœ ëª¨ë¸ ì„±ëŠ¥ í‘œì‹œ
            report_opt = classification_report(y_test_opt, y_pred_opt, output_dict=True)
            st.write("**ìµœì í™”ëœ ëª¨ë¸ ì„±ëŠ¥:**")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ì •í™•ë„", f"{report_opt['accuracy']:.3f}")
            with col2:
                st.metric("ì •ë°€ë„", f"{report_opt['1']['precision']:.3f}")
            with col3:
                st.metric("ì¬í˜„ìœ¨", f"{report_opt['1']['recall']:.3f}")
            with col4:
                st.metric("F1-Score", f"{report_opt['1']['f1-score']:.3f}")
    
    # ì €ì¥ëœ ëª¨ë¸ ì‚¬ìš©
    elif saved_model is not None:
        st.success("âœ… ì €ì¥ëœ ìµœì í™” ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        st.write("**ì €ì¥ëœ ëª¨ë¸ ì •ë³´:**")
        st.json(saved_model['best_params'])
        
        # ì €ì¥ëœ ëª¨ë¸ë¡œ ì˜ˆì¸¡ ê¸°ëŠ¥ ì¶”ê°€
        st.subheader("ğŸ¯ ê°œì¸ ë‡Œì¡¸ì¤‘ ìœ„í—˜ ì˜ˆì¸¡")
        
        with st.form("prediction_form"):
            col1, col2 = st.columns(2)
            
            with col1:
                age = st.number_input("ë‚˜ì´", min_value=0, max_value=120, value=50)
                gender = st.selectbox("ì„±ë³„", ["Male", "Female"])
                hypertension = st.selectbox("ê³ í˜ˆì••", [0, 1])
                heart_disease = st.selectbox("ì‹¬ì¥ë³‘", [0, 1])
                ever_married = st.selectbox("ê²°í˜¼ ì—¬ë¶€", ["Yes", "No"])
            
            with col2:
                work_type = st.selectbox("ì§ì—… ìœ í˜•", ["Private", "Self-employed", "Govt_job", "children", "Never_worked"])
                residence_type = st.selectbox("ê±°ì£¼ ìœ í˜•", ["Urban", "Rural"])
                avg_glucose_level = st.number_input("í‰ê·  í˜ˆë‹¹ ìˆ˜ì¹˜", min_value=50.0, max_value=300.0, value=100.0)
                bmi = st.number_input("BMI", min_value=10.0, max_value=50.0, value=25.0)
                smoking_status = st.selectbox("í¡ì—° ìƒíƒœ", ["formerly smoked", "never smoked", "smokes", "Unknown"])
            
            submitted = st.form_submit_button("ì˜ˆì¸¡í•˜ê¸°")
            
            if submitted:
                # ì…ë ¥ ë°ì´í„° ìƒì„±
                input_data = pd.DataFrame({
                    'age': [age],
                    'gender': [gender],
                    'hypertension': [hypertension],
                    'heart_disease': [heart_disease],
                    'ever_married': [ever_married],
                    'work_type': [work_type],
                    'Residence_type': [residence_type],
                    'avg_glucose_level': [avg_glucose_level],
                    'bmi': [bmi],
                    'smoking_status': [smoking_status]
                })
                
                # ì „ì²˜ë¦¬ ë° ì˜ˆì¸¡
                input_preprocessed = saved_model['preprocessor'].transform(input_data)
                prediction = saved_model['model'].predict(input_preprocessed)
                prediction_proba = saved_model['model'].predict_proba(input_preprocessed)
                
                # ê²°ê³¼ í‘œì‹œ
                if prediction[0] == 1:
                    st.error("âš ï¸ ë‡Œì¡¸ì¤‘ ìœ„í—˜ì´ ë†’ìŠµë‹ˆë‹¤!")
                    st.write(f"ë‡Œì¡¸ì¤‘ ë°œìƒ í™•ë¥ : {prediction_proba[0][1]:.2%}")
                else:
                    st.success("âœ… ë‡Œì¡¸ì¤‘ ìœ„í—˜ì´ ë‚®ìŠµë‹ˆë‹¤.")
                    st.write(f"ë‡Œì¡¸ì¤‘ ë°œìƒ í™•ë¥ : {prediction_proba[0][1]:.2%}")
                
                # ìœ„í—˜ë„ ì‹œê°í™”
                fig = px.bar(
                    x=['ë‡Œì¡¸ì¤‘ ì—†ìŒ', 'ë‡Œì¡¸ì¤‘ ìˆìŒ'],
                    y=prediction_proba[0],
                    title="ë‡Œì¡¸ì¤‘ ë°œìƒ í™•ë¥ ",
                    labels={'x': 'ê²°ê³¼', 'y': 'í™•ë¥ '}
                )
                fig.update_layout(yaxis_range=[0, 1])
                st.plotly_chart(fig, use_container_width=True)
    
    # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    report = classification_report(y_test, y_pred, output_dict=True)
    conf_matrix = confusion_matrix(y_test, y_pred)
    
    # ì„±ëŠ¥ ì§€í‘œ í‘œì‹œ
    st.subheader("ğŸ¯ ëª¨ë¸ ì„±ëŠ¥")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ì •í™•ë„", f"{report['accuracy']:.3f}")
    with col2:
        st.metric("ì •ë°€ë„", f"{report['1']['precision']:.3f}")
    with col3:
        st.metric("ì¬í˜„ìœ¨", f"{report['1']['recall']:.3f}")
    with col4:
        st.metric("F1-Score", f"{report['1']['f1-score']:.3f}")
    
    # ì¶”ê°€ í†µê³„ ì§€í‘œ ê³„ì‚°
    y_pred_proba = model.predict_proba(X_test_preprocessed)
    mcc, kappa, bal_acc = calculate_statistics(y_test, y_pred, y_pred_proba)
    
    st.subheader("ğŸ“Š ì¶”ê°€ í†µê³„ ì§€í‘œ")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Matthews Correlation", f"{mcc:.3f}")
    with col2:
        st.metric("Cohen's Kappa", f"{kappa:.3f}")
    with col3:
        st.metric("Balanced Accuracy", f"{bal_acc:.3f}")
    
    # ì‹œê°í™” ì„¹ì…˜
    st.subheader("ğŸ“ˆ ë¶„ì„ ê²°ê³¼ ì‹œê°í™”")
    
    # íƒ­ìœ¼ë¡œ êµ¬ë¶„
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs([
        "í˜¼ë™ í–‰ë ¬", "íŠ¹ì„± ì¤‘ìš”ë„", "ì¸êµ¬í†µê³„ ë¶„ì„", "ì„±ëŠ¥ ì§€í‘œ", 
        "í•™ìŠµ ê³¡ì„ ", "ROC ì»¤ë¸Œ", "ìƒê´€ê´€ê³„ Heatmap", "Optuna ìµœì í™” ê³¼ì •"
    ])
    
    with tab1:
        # í˜¼ë™ í–‰ë ¬
        fig = go.Figure(data=go.Heatmap(
            z=conf_matrix,
            x=['ë‡Œì¡¸ì¤‘ ì—†ìŒ', 'ë‡Œì¡¸ì¤‘ ìˆìŒ'],
            y=['ë‡Œì¡¸ì¤‘ ì—†ìŒ', 'ë‡Œì¡¸ì¤‘ ìˆìŒ'],
            colorscale='Blues',
            text=conf_matrix,
            texttemplate="%{text}",
            textfont={"size": 16}
        ))
        fig.update_layout(
            title="í˜¼ë™ í–‰ë ¬ (Confusion Matrix)",
            xaxis_title="ì˜ˆì¸¡ê°’",
            yaxis_title="ì‹¤ì œê°’"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        # íŠ¹ì„± ì¤‘ìš”ë„
        top_features = feature_importance.head(10)
        fig = px.bar(
            top_features, 
            x='importance', 
            y='feature',
            orientation='h',
            title="ìƒìœ„ 10ê°œ íŠ¹ì„± ì¤‘ìš”ë„"
        )
        fig.update_layout(xaxis_title="ì¤‘ìš”ë„", yaxis_title="íŠ¹ì„±")
        st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        # ì¸êµ¬í†µê³„ ë¶„ì„
        col1, col2 = st.columns(2)
        
        with col1:
            # ì—°ë ¹ëŒ€ë³„ ë‡Œì¡¸ì¤‘ ë°œìƒë¥ 
            df['age_group'] = pd.cut(df['age'], 
                                    bins=[0, 20, 40, 60, 80, 100], 
                                    labels=['0-20', '21-40', '41-60', '61-80', '80+'])
            age_stroke_rate = df.groupby('age_group')['stroke'].mean()
            
            fig = px.bar(
                x=age_stroke_rate.index,
                y=age_stroke_rate.values,
                title="ì—°ë ¹ëŒ€ë³„ ë‡Œì¡¸ì¤‘ ë°œìƒë¥ ",
                labels={'x': 'ì—°ë ¹ëŒ€', 'y': 'ë‡Œì¡¸ì¤‘ ë°œìƒë¥ '}
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # ì„±ë³„ ë‡Œì¡¸ì¤‘ ë°œìƒë¥ 
            gender_stroke_rate = df.groupby('gender')['stroke'].mean()
            fig = px.bar(
                x=gender_stroke_rate.index,
                y=gender_stroke_rate.values,
                title="ì„±ë³„ ë‡Œì¡¸ì¤‘ ë°œìƒë¥ ",
                labels={'x': 'ì„±ë³„', 'y': 'ë‡Œì¡¸ì¤‘ ë°œìƒë¥ '}
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with tab4:
        # ì„±ëŠ¥ ì§€í‘œ ë¹„êµ
        metrics = ['ì •í™•ë„', 'ì •ë°€ë„', 'ì¬í˜„ìœ¨', 'F1-Score']
        values = [report['accuracy'], report['1']['precision'], 
                 report['1']['recall'], report['1']['f1-score']]
        
        fig = px.bar(
            x=metrics,
            y=values,
            title="ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ ë¹„êµ",
            labels={'x': 'ì§€í‘œ', 'y': 'ì ìˆ˜'}
        )
        fig.update_layout(yaxis_range=[0, 1])
        st.plotly_chart(fig, use_container_width=True)
    
    with tab5:
        # í•™ìŠµ ê³¡ì„ 
        with st.spinner('í•™ìŠµ ê³¡ì„  ê³„ì‚° ì¤‘...'):
            X_train_preprocessed = preprocessor.transform(X_train)
            learning_fig = plot_learning_curve(model, X_train_preprocessed, y_train)
            st.plotly_chart(learning_fig, use_container_width=True)
    
    with tab6:
        # ROC ì»¤ë¸Œ
        with st.spinner('ROC ì»¤ë¸Œ ê³„ì‚° ì¤‘...'):
            roc_fig, roc_auc = plot_roc_curve(y_test, y_pred_proba)
            st.plotly_chart(roc_fig, use_container_width=True)
            st.info(f"ROC AUC: {roc_auc:.3f}")
    
    with tab7:
        # ìƒê´€ê´€ê³„ Heatmap
        with st.spinner('ìƒê´€ê´€ê³„ Heatmap ê³„ì‚° ì¤‘...'):
            correlation_fig = plot_correlation_heatmap(df)
            st.plotly_chart(
                correlation_fig, 
                use_container_width=True,
                config=dict(displayModeBar=False)
            )
            
            # ìƒê´€ê´€ê³„ ì„¤ëª… ì¶”ê°€
            st.subheader("ğŸ“Š ìƒê´€ê´€ê³„ ë¶„ì„ ì„¤ëª…")
            st.write("""
            **ìƒê´€ê´€ê³„ í•´ì„:**
            - **1.0 (ë¹¨ê°„ìƒ‰)**: ì™„ë²½í•œ ì–‘ì˜ ìƒê´€ê´€ê³„
            - **0.0 (í°ìƒ‰)**: ìƒê´€ê´€ê³„ ì—†ìŒ
            - **-1.0 (íŒŒë€ìƒ‰)**: ì™„ë²½í•œ ìŒì˜ ìƒê´€ê´€ê³„
            
            **ì£¼ìš” ë°œê²¬ì‚¬í•­:**
            - ë‡Œì¡¸ì¤‘ê³¼ ê°€ì¥ ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ë³´ì´ëŠ” ë³€ìˆ˜ë“¤ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
            - ë³€ìˆ˜ ê°„ ë‹¤ì¤‘ê³µì„ ì„±ì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
            """)
            
            # ë‡Œì¡¸ì¤‘ê³¼ì˜ ìƒê´€ê´€ê³„ ìˆœìœ„ í‘œì‹œ
            numeric_df = df.select_dtypes(include=['int64', 'float64'])
            stroke_corr = numeric_df.corr()['stroke'].sort_values(ascending=False)
            
            st.subheader("ğŸ¯ ë‡Œì¡¸ì¤‘ê³¼ì˜ ìƒê´€ê´€ê³„ ìˆœìœ„")
            corr_df = pd.DataFrame({
                'ë³€ìˆ˜': stroke_corr.index,
                'ìƒê´€ê³„ìˆ˜': stroke_corr.values
            })
            st.dataframe(corr_df, use_container_width=True)
            
            # ìƒê´€ê´€ê³„ê°€ ë†’ì€ ë³€ìˆ˜ë“¤ ì‹œê°í™”
            high_corr_vars = stroke_corr[abs(stroke_corr) > 0.1].index.tolist()
            if len(high_corr_vars) > 1:  # stroke ì œì™¸í•˜ê³  1ê°œ ì´ìƒ
                st.subheader("ğŸ“ˆ ë†’ì€ ìƒê´€ê´€ê³„ ë³€ìˆ˜ë“¤")
                fig = px.bar(
                    x=high_corr_vars,
                    y=stroke_corr[high_corr_vars].values,
                    title="ë‡Œì¡¸ì¤‘ê³¼ ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ë³´ì´ëŠ” ë³€ìˆ˜ë“¤",
                    labels={'x': 'ë³€ìˆ˜', 'y': 'ìƒê´€ê³„ìˆ˜'}
                )
                fig.update_layout(yaxis_range=[-1, 1])
                st.plotly_chart(fig, use_container_width=True)
    
    with tab8:
        # Optuna ìµœì í™” ê³¼ì • (ìµœì í™”ê°€ ì‹¤í–‰ëœ ê²½ìš°ì—ë§Œ í‘œì‹œ)
        if 'study' in globals():
            # ìµœì í™” ê³¼ì • ì‹œê°í™”
            fig = go.Figure()
            
            # ìµœì í™” ê³¼ì •ì˜ ì ìˆ˜ ë³€í™”
            trials = study.trials
            scores = [trial.value for trial in trials if trial.value is not None]
            trial_numbers = list(range(1, len(scores) + 1))
            
            fig.add_trace(go.Scatter(
                x=trial_numbers,
                y=scores,
                mode='lines+markers',
                name='F1 Score',
                line=dict(color='blue')
            ))
            
            fig.update_layout(
                title="Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ê³¼ì •",
                xaxis_title="ì‹œë„ íšŸìˆ˜",
                yaxis_title="F1 Score",
                showlegend=True
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # ìµœì í™” ê³¼ì • ìƒì„¸ ì •ë³´
            st.write("**ìµœì í™” ê³¼ì • ìƒì„¸ ì •ë³´:**")
            st.write(f"- ì´ ì‹œë„ íšŸìˆ˜: {len(trials)}")
            st.write(f"- ìµœê³  ì ìˆ˜: {study.best_value:.4f}")
            st.write(f"- ìµœì  íŒŒë¼ë¯¸í„°: {study.best_params}")
        else:
            st.info("í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ ì‹¤í–‰í•˜ë©´ ìµœì í™” ê³¼ì •ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # ìƒì„¸ ë¶„ì„ ê²°ê³¼
    st.subheader("ğŸ“‹ ìƒì„¸ ë¶„ì„ ê²°ê³¼")
    
    with st.expander("ë¶„ë¥˜ ë³´ê³ ì„œ"):
        st.text(classification_report(y_test, y_pred))
    
    with st.expander("íŠ¹ì„± ì¤‘ìš”ë„ ìƒì„¸"):
        st.dataframe(feature_importance, use_container_width=True)
    
    # ë°ì´í„° ë¶„í¬ ë¶„ì„
    st.subheader("ğŸ“Š ë°ì´í„° ë¶„í¬ ë¶„ì„")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬
        stroke_counts = df['stroke'].value_counts()
        fig = px.pie(
            values=stroke_counts.values,
            names=['ë‡Œì¡¸ì¤‘ ì—†ìŒ', 'ë‡Œì¡¸ì¤‘ ìˆìŒ'],
            title="íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # ì—°ë ¹ ë¶„í¬
        fig = px.histogram(
            df, 
            x='age', 
            nbins=20,
            title="ì—°ë ¹ ë¶„í¬"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„í¬
    categorical_cols = df.select_dtypes(include=['object']).columns
    if len(categorical_cols) > 0:
        st.subheader("ğŸ“Š ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„í¬")
        
        for col in categorical_cols:
            fig = px.bar(
                x=df[col].value_counts().index,
                y=df[col].value_counts().values,
                title=f"{col} ë¶„í¬",
                labels={'x': col, 'y': 'ë¹ˆë„'}
            )
            st.plotly_chart(fig, use_container_width=True)

if __name__ == "__main__":
    main() 