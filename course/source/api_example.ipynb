{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8KuSgoSek_df"},"outputs":[],"source":["\n","# 사전설치 : pip install kss textblob torch\n","# 허깅페이스 로그인 접속 : pip install huggingface_hub, 터미널에서 huggingface-cli login, settings> Access Token에서 토큰 생성 후 액세스 토큰 입력\n","import os\n","import gradio as gr\n","import requests\n","import re\n","import json\n","from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n","import kss  # kss는 \"Korean Sentence Splitter\"의 약자로, 한국어 문장 분리 도구\n","from textblob import TextBlob\n","import numpy as np\n","import torch\n","import warnings\n","warnings.filterwarnings('ignore')   # 파이썬의 warnings 모듈을 사용하여 발생하는 경고 메시지를 무시"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jtNTI-RKk_di"},"outputs":[],"source":["# Gemini API 키 설정\n","os.environ[\"GEMINI_API_KEY\"] = \"insert your api key\"  # 발급받은 Gemini API 키"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xNG9By7pk_dl"},"outputs":[],"source":["class NewsAnalyzer:\n","    def __init__(self):\n","        print(\"모델 초기화 중...\")\n","\n","        # 감성 분석 모델 초기화\n","        print(\"감성 분석 모델 로딩...\")\n","        self.sentiment_analyzer = pipeline(\n","            \"sentiment-analysis\",\n","            model=\"snunlp/KR-FinBert-SC\",\n","            tokenizer=\"snunlp/KR-FinBert-SC\"\n","        )\n","\n","        # 가짜 뉴스 분류 모델 초기화\n","        print(\"가짜 뉴스 분류 모델 로딩...\")\n","        self.init_fake_news_classifier()\n","\n","        print(\"모델 초기화 완료!\")\n","\n","    def init_fake_news_classifier(self):\n","        \"\"\"가짜 뉴스 분류 모델 초기화\"\"\"\n","        try:\n","            # 'beomi/kcbert-base' 모델 사용 - 한국어에 더 특화된 모델\n","            model_name = \"beomi/kcbert-base\"\n","            self.fake_news_classifier = pipeline(\n","                \"text-classification\",\n","                model=model_name,\n","                tokenizer=model_name\n","            )\n","\n","            def classify_long_text(text):\n","                try:\n","                    # 한국어 문장 분리\n","                    sentences = kss.split_sentences(text)  # 텍스트를 문장 단위로 분리\n","                    chunks = []\n","                    current_chunk = \"\"\n","\n","                    # 청크 생성\n","                    for sentence in sentences:\n","                        if len(current_chunk) + len(sentence) < 1000:  # 1000자 미만의 청크 생성\n","                            current_chunk += sentence + \" \"\n","                        else:\n","                            if current_chunk:\n","                                chunks.append(current_chunk.strip())\n","                            current_chunk = sentence + \" \"\n","                    if current_chunk:\n","                        chunks.append(current_chunk.strip())\n","\n","                    if not chunks:\n","                        chunks = [text]\n","\n","                    # 각 청크에 대해 분류 수행\n","                    results = []\n","                    for chunk in chunks:\n","                        try:\n","                            result = self.fake_news_classifier(chunk[:512])  # 청크의 처음 512자만 사용하도록 제한\n","\n","                            # 신뢰도 점수 계산 - 문장의 특성에 따라 가중치 부여\n","                            score = result[0]['score']\n","\n","                            # 가짜뉴스 특성 체크\n","                            fake_news_indicators = self.check_fake_news_indicators(chunk)  # 청크에서 가짜 뉴스 관련 특징을 확인\n","\n","                            # 최종 점수 조정\n","                            adjusted_score = self.adjust_score(score, fake_news_indicators)  # 기본 점수를 가짜 뉴스 특징에 따라 조정\n","                            results.append(adjusted_score)\n","\n","                        except Exception as e:\n","                            print(f\"청크 처리 중 오류: {str(e)}\")\n","                            continue\n","\n","                    # 결과 평균 계산 및 레이블 결정\n","                    if results:\n","                        avg_score = np.mean(results)  # 청크들의 점수 평균을 계산\n","                        # 점수가 0.6 이상일 때 가짜뉴스로 판정 (임계값 조정)\n","                        final_label = 'FAKE' if avg_score > 0.6 else 'REAL'\n","                        return [{\"label\": final_label, \"score\": avg_score}]\n","                    else:\n","                        return [{\"label\": \"UNKNOWN\", \"score\": 0.5}]\n","\n","                except Exception as e:\n","                    print(f\"텍스트 분류 중 오류: {str(e)}\")\n","                    return [{\"label\": \"UNKNOWN\", \"score\": 0.5}]\n","\n","            self.classify_text = classify_long_text\n","\n","        except Exception as e:\n","            print(f\"가짜 뉴스 분류 모델 로딩 실패: {str(e)}\")\n","            self.classify_text = lambda x: [{\"label\": \"UNKNOWN\", \"score\": 0.5}]\n","\n","    def check_fake_news_indicators(self, text):\n","        \"\"\"가짜뉴스 특성 체크\"\"\"\n","        indicators = {\n","            'excessive_punctuation': len(re.findall(r'[!?]{2,}', text)) > 0,\n","            'all_caps_words': len(re.findall(r'\\b[A-Z가-힣]{3,}\\b', text)) > 0,\n","            'sensational_words': any(word in text.lower() for word in [\n","                '충격', '경악', '발칵', '화들짝', '헉', '대박', '경악',\n","                '충격적', '전격', '초특급', '극비', '특종', '단독'\n","            ]),\n","            'unverified_sources': any(phrase in text for phrase in [\n","                '카더라', '라고 한다', '했다고 한다', '라는 소문',\n","                '알려졌다', '전해졌다', '...', '소식통'\n","            ])\n","        }\n","        return indicators\n","\n","    def adjust_score(self, base_score, indicators):\n","        \"\"\"지표에 따른 점수 조정\"\"\"\n","        score = base_score\n","\n","        # 각 지표별 가중치 적용\n","        if indicators['excessive_punctuation']:  # 과도한 문장 부호 사용\n","            score += 0.1\n","        if indicators['all_caps_words']:  # 모든 글자가 대문자인 단어 사용\n","            score += 0.1\n","        if indicators['sensational_words']:  # 선정적인 단어 사용\n","            score += 0.15\n","        if indicators['unverified_sources']:  # 확인되지 않은 출처 인용\n","            score += 0.15\n","\n","        # 점수 범위 제한 (0~1)\n","        return min(max(score, 0), 1)\n","\n","    def analyze_with_gemini(self, article):\n","        \"\"\"Gemini API를 사용한 분석\"\"\"\n","        if not os.environ.get(\"GEMINI_API_KEY\") or os.environ[\"GEMINI_API_KEY\"] == \"your-gemini-api-key-here\":\n","            return \"Gemini API 키가 설정되지 않았습니다.\"\n","\n","        try:\n","            url = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"\n","            headers = {\n","                'Content-Type': 'application/json',\n","                'x-goog-api-key': os.environ['GEMINI_API_KEY']\n","            }\n","\n","            max_chunk_length = 4000\n","            chunks = [article[i:i + max_chunk_length] for i in range(0, len(article), max_chunk_length)]\n","\n","            analyses = []\n","            for chunk in chunks[:3]:\n","                prompt = (\n","                    \"다음 뉴스 기사의 진위 여부를 분석해주세요. 다음 항목별로 평가해주세요:\\n\"\n","                    \"1. 기사의 객관성\\n\"\n","                    \"2. 사실 확인 가능한 정보의 존재 여부\\n\"\n","                    \"3. 감정적 표현이나 과장된 표현의 사용\\n\"\n","                    \"4. 출처와 인용의 명확성\\n\\n\"\n","                    f\"기사 내용:\\n{chunk}\"\n","                )\n","\n","                data = {\"contents\": [{\"parts\": [{\"text\": prompt}]}]}\n","\n","                response = requests.post(url, headers=headers, json=data)\n","                response.raise_for_status()\n","                result = response.json()\n","                analyses.append(result['candidates'][0]['content']['parts'][0]['text'])\n","\n","            return \"\\n\\n\".join(analyses)\n","\n","        except Exception as e:\n","            return f\"Gemini 분석 중 오류 발생: {str(e)}\"\n","\n","    def analyze_sentiment_details(self, article):\n","        \"\"\"세부적인 감성 분석\"\"\"\n","        try:\n","            sentences = kss.split_sentences(article)\n","            sentiment_scores = []\n","\n","            for sentence in sentences[:50]:\n","                try:\n","                    sentiment_result = self.sentiment_analyzer(sentence[:512])[0]\n","                    score = (float(sentiment_result['score']) - 0.5) * 2\n","                    sentiment_scores.append(score)\n","                except Exception as e:\n","                    print(f\"문장 감성 분석 중 오류: {str(e)}\")\n","                    continue\n","\n","            if sentiment_scores:\n","                return {\n","                    \"평균_감성점수\": np.mean(sentiment_scores),\n","                    \"감성_변동성\": np.std(sentiment_scores),\n","                    \"극단적_문장_비율\": len([s for s in sentiment_scores if abs(s) > 0.5]) / len(sentiment_scores)\n","                }\n","            else:\n","                return {\n","                    \"평균_감성점수\": 0,\n","                    \"감성_변동성\": 0,\n","                    \"극단적_문장_비율\": 0\n","                }\n","        except Exception as e:\n","            print(f\"감성 분석 중 오류 발생: {str(e)}\")\n","            return {\n","                \"평균_감성점수\": 0,\n","                \"감성_변동성\": 0,\n","                \"극단적_문장_비율\": 0\n","            }\n","\n","    def analyze_news(self, article):\n","        \"\"\"통합 뉴스 분석\"\"\"\n","        if not article or len(article.strip()) == 0:\n","            return \"분석할 텍스트를 입력해주세요.\"\n","\n","        try:\n","            # 1. Gemini 분석\n","            gemini_analysis = self.analyze_with_gemini(article)\n","\n","            # 2. 가짜 뉴스 분류기 분석\n","            fake_news_result = self.classify_text(article)\n","\n","            # 3. 감성 분석\n","            sentiment_details = self.analyze_sentiment_details(article)\n","\n","            # 4. 신뢰도 계산 (가짜뉴스 점수를 반전)\n","            credibility_score = (1 - float(fake_news_result[0]['score'])) * 100\n","\n","            # 판정 기준 변경: 점수가 40% 미만이면 가짜뉴스\n","            is_fake = credibility_score < 40\n","\n","            # 결과 텍스트 생성\n","            result = f\"\"\"\n","=== 뉴스 진위 분석 결과 ===\n","\n","[최종 판정]\n","{'가짜 뉴스' if is_fake else '진짜 뉴스'} (신뢰도: {round(credibility_score, 2)}%)\n","\n","[상세 분석]\n","1. AI 모델 분석:\n","   - 판정: {'FAKE' if is_fake else 'REAL'}\n","   - 신뢰도: {round(credibility_score, 2)}%\n","\n","2. 감성 분석:\n","   - 감정 강도: {round(abs(sentiment_details['평균_감성점수']) * 100, 2)}%\n","   - 극단적 표현 비율: {round(sentiment_details['극단적_문장_비율'] * 100, 2)}%\n","\n","3. Gemini 분석:\n","{gemini_analysis}\n","\n","※ 주의: 이 분석은 참고용이며, 최종적인 판단은 전문가의 검증이 필요합니다.\n","\"\"\"\n","            return result\n","\n","        except Exception as e:\n","            return f\"\"\"\n","=== 오류 발생 ===\n","분석 중 문제가 발생했습니다: {str(e)}\n","시스템 관리자에게 문의하세요.\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"txZfh69Zk_dq"},"outputs":[],"source":["def create_interface():\n","    analyzer = NewsAnalyzer()\n","\n","    iface = gr.Interface(\n","        fn=analyzer.analyze_news,\n","        inputs=gr.Textbox(lines=10, placeholder=\"뉴스 기사 내용을 입력하세요...\"),\n","        outputs=gr.Textbox(lines=20),\n","        title=\"가짜 뉴스 판별 시스템\",\n","        description=\"AI 모델을 활용한 뉴스 진위 판별 시스템\"\n","    )\n","    return iface"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H09yuPEmk_ds","outputId":"e6c35e32-4299-46e8-bea0-7feaba430eec"},"outputs":[{"name":"stdout","output_type":"stream","text":["모델 초기화 중...\n","감성 분석 모델 로딩...\n"]},{"name":"stderr","output_type":"stream","text":["Device set to use cpu\n"]},{"name":"stdout","output_type":"stream","text":["가짜 뉴스 분류 모델 로딩...\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Device set to use cpu\n"]},{"name":"stdout","output_type":"stream","text":["모델 초기화 완료!\n","모델 초기화 중...\n","감성 분석 모델 로딩...\n"]},{"name":"stderr","output_type":"stream","text":["Device set to use cpu\n"]},{"name":"stdout","output_type":"stream","text":["가짜 뉴스 분류 모델 로딩...\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Device set to use cpu\n"]},{"name":"stdout","output_type":"stream","text":["모델 초기화 완료!\n","* Running on local URL:  http://127.0.0.1:7860\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"data":{"text/html":["<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["if __name__ == \"__main__\":\n","    analyzer = NewsAnalyzer()\n","    iface = create_interface()\n","    iface.launch()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KJit2t7gk_du","outputId":"c924e7a9-7a6c-4c18-aec5-84db30e33ec2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Closing server running on port: 7860\n"]}],"source":["iface.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ViUuiwh1k_dw"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}