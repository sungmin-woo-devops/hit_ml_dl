{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mNU_sMVgB0cV","outputId":"60f1a4c4-cfd4-4e4c-aa99-4b098dbb1801"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\99.참고자료\\04.교육\\소스코드\\mlPrjoct\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import gradio as gr\n","from langchain_community.document_loaders import TextLoader, DirectoryLoader\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.vectorstores import Chroma\n","from langchain.chains import RetrievalQA\n","from langchain_community.chat_models import ChatOllama\n","from langchain.prompts import PromptTemplate\n","from langchain.chains import ConversationalRetrievalChain\n","from langchain.schema import Document\n","from langchain.memory import ConversationBufferMemory\n","import os\n","import shutil\n","from PIL import Image\n","import base64\n","from io import BytesIO\n","from langchain_core.messages import HumanMessage\n","from datetime import datetime\n","from matplotlib import rcParams\n","from wordcloud import WordCloud\n","import matplotlib.pyplot as plt\n","import glob"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Z7PKBFnB0cX"},"outputs":[],"source":["# 폰트 경로 설정 (워드 클라우드용)\n","# FONT_PATH = '/usr/share/fonts/nhn_nanum/NanumGothic.ttf'\n","\n","# 워드클라우드 폰트 경로 (Windows 기준)\n","FONT_PATH = \"C:\\\\Windows\\\\Fonts\\\\malgun.ttf\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VKQ-tSswB0cY"},"outputs":[],"source":["# 파일 경로 설정\n","MAIN_DOC_PATH = './dataset/dbvision02.txt'\n","BASE_DIR = os.getcwd()  # 현재 작업 디렉터리를 기준으로 설정\n","TEMP_FOLDER = os.path.join(BASE_DIR, \"temp\")  # temp 폴더의 절대 경로\n","# TEMP_FOLDER = './temp'\n","IMG_PATH = './imgs/wordcloud.png'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C15hbcbAB0cY"},"outputs":[],"source":["# 문서 로드 및 벡터 저장소 초기화 함수\n","def initialize_db(file_path=None, use_main_only=True):\n","    \"\"\"\n","    문서를 로드하고 벡터 저장소를 초기화하는 함수\n","\n","    Parameters:\n","    file_path (str): 로드할 파일 경로. None인 경우 MAIN_DOC_PATH 사용\n","    use_main_only (bool): True인 경우 MAIN_DOC_PATH만 사용, False인 경우 지정된 파일만 사용\n","    \"\"\"\n","    try:\n","        # 사용할 문서 경로 결정\n","        doc_path = MAIN_DOC_PATH if use_main_only else file_path\n","        if not doc_path:\n","            raise ValueError(\"파일 경로가 지정되지 않았습니다.\")\n","\n","        if not os.path.exists(doc_path):\n","            if doc_path == MAIN_DOC_PATH:\n","                with open(doc_path, 'w', encoding='utf-8') as f:\n","                    f.write(\"휴먼(주) 정보:\\n\")\n","                print(f\"새 파일이 생성되었습니다: {doc_path}\")\n","            else:\n","                raise FileNotFoundError(f\"파일을 찾을 수 없습니다: {doc_path}\")\n","\n","        # 문서 로드\n","        loader = TextLoader(doc_path, encoding='utf-8')\n","        docs = loader.load()\n","\n","        # 임베딩 모델 및 벡터 저장소 초기화\n","        embeddings_model = HuggingFaceEmbeddings(\n","            model_name='sentence-transformers/all-MiniLM-L6-v2'\n","        )\n","        db = Chroma.from_documents(docs, embeddings_model)\n","\n","        return db, embeddings_model\n","\n","    except Exception as e:\n","        print(f\"DB 초기화 중 오류 발생: {str(e)}\")\n","        raise"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iVse0S2OB0cZ"},"outputs":[],"source":["# 새로운 파일(txt) 추가\n","def add_new_file(file):\n","    if file is None:\n","        return \"파일을 선택해주세요.\", None\n","\n","    try:\n","        file_path = os.path.join(TEMP_FOLDER, os.path.basename(file.name))\n","        shutil.copy2(file.name, file_path)\n","\n","        # 파일 크기 확인 및 유효성 검사\n","        file_size = os.path.getsize(file_path)\n","        if file_size == 0:\n","            os.remove(file_path)  # 크기 0인 파일 삭제\n","            return \"파일이 비어 있습니다. 다시 시도해 주세요.\", None\n","\n","        # 벡터 저장소 재초기화\n","        global db, embeddings_model, qa_chain\n","        db, embeddings_model = initialize_db()\n","        qa_chain = initialize_qa_chain()\n","\n","        return f\"파일이 성공적으로 추가되었습니다: {file.name}\", None\n","    except Exception as e:\n","        return f\"파일 추가 중 오류가 발생했습니다: {str(e)}\", None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IqYheIqnB0cZ"},"outputs":[],"source":["# 새로운 정보 추가 함수\n","def add_new_information(new_info):\n","    if new_info.strip():\n","        try:\n","            with open(MAIN_DOC_PATH, 'a', encoding='utf-8') as f:\n","                f.write(f\"\\n{new_info.strip()}\")\n","\n","            # 벡터 저장소 재초기화\n","            global db, embeddings_model, qa_chain\n","            db, embeddings_model = initialize_db()\n","            qa_chain = initialize_qa_chain()\n","\n","            return \"새로운 정보가 성공적으로 추가되었습니다.\"\n","        except Exception as e:\n","            return f\"정보 추가 중 오류가 발생했습니다: {str(e)}\"\n","    return \"추가할 정보를 입력해주세요.\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9aKMK6ZfB0ca"},"outputs":[],"source":["def read_file_content(file_path):\n","    try:\n","        # UTF-8로 시도\n","        with open(file_path, 'r', encoding='utf-8') as f:\n","            return f.read().strip()\n","    except UnicodeDecodeError:\n","        try:\n","            # CP949 인코딩으로 시도 (한국어 텍스트에 자주 사용)\n","            with open(file_path, 'r', encoding='cp949') as f:\n","                return f.read().strip()\n","        except Exception as e:\n","            return f\"(파일 읽기 오류: {str(e)})\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w4wibWHYB0ca"},"outputs":[],"source":["def view_all_content():\n","    content = \"\"\n","\n","    # 메인 문서 내용\n","    try:\n","        with open(MAIN_DOC_PATH, 'r', encoding='utf-8') as f:\n","            content += \"=== 메인 문서 내용 ===\\n\"\n","            content += f.read().strip() + \"\\n\\n\"\n","    except FileNotFoundError:\n","        content += \"메인 문서가 없습니다.\\n\\n\"\n","\n","    # temp 폴더 내 문서들의 내용\n","    if os.path.exists(TEMP_FOLDER):\n","        for filename in os.listdir(TEMP_FOLDER):\n","            if filename.endswith('.txt'):\n","                file_path = os.path.abspath(os.path.join(TEMP_FOLDER, filename))\n","                file_content = read_file_content(file_path)\n","\n","                if file_content:\n","                    content += f\"=== {filename} ===\\n{file_content}\\n\\n\"\n","                else:\n","                    content += f\"=== {filename} ===\\n(내용이 비어 있습니다)\\n\\n\"\n","    else:\n","        content += \"temp 폴더가 존재하지 않습니다.\\n\\n\"\n","\n","    return content"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JTQWA1O9B0ca"},"outputs":[],"source":["# Base64 변환 함수\n","def convert_to_base64(image):\n","    buffered = BytesIO()\n","    image.save(buffered, format=\"JPEG\")\n","    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n","    return img_str"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AuR6tEieB0cb","outputId":"8c05323b-e84a-45d9-d1d6-0c178d1f6fe8"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\ahnda\\AppData\\Local\\Temp\\ipykernel_9836\\192935699.py:29: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n","  embeddings_model = HuggingFaceEmbeddings(\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\99.참고자료\\04.교육\\소스코드\\mlPrjoct\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n","\n"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["# 초기 DB 및 embeddings_model 설정\n","db, embeddings_model = initialize_db()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z346xVH6B0cb"},"outputs":[],"source":["# 메모리 설정\n","memory = ConversationBufferMemory(\n","    memory_key=\"chat_history\",\n","    output_key=\"answer\",  # 출력 키를 명시적으로 지정\n","    return_messages=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qcY3rw9lB0cb"},"outputs":[],"source":["# 프롬프트 템플릿 정의\n","prompt_template = \"\"\"\n","당신은 휴먼(주) 정보를 제공하는 AI 어시스턴트입니다. 모든 답변은 한국어로 답변해 주세요.\n","\n","아래는 이전 대화 내용입니다:\n","{chat_history}\n","\n","관련 문서 내용:\n","{context}\n","\n","사용자 질문: {question}\n","\n","지침:\n","1. 문서에서 찾은 정보가 있다면 그 정보를 바탕으로 답변해주세요.\n","2. 문서에서 관련 정보를 찾지 못했다면 \"죄송합니다만, 해당 질문에 대한 정보를 문서에서 찾을 수 없습니다.\"라고 답변한 후, 일반적인 대화를 이어갈 수 있습니다.\n","3. 모든 답변은 친절하고 전문적으로 제공해주세요.\n","\n","답변:\n","\"\"\"\n","\n","PROMPT = PromptTemplate(\n","    template=prompt_template,\n","    input_variables=[\"chat_history\", \"context\", \"question\"]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A44k6hWzB0cb"},"outputs":[],"source":["# LLM 모델 설정\n","llm = ChatOllama(model=\"gemma2\", temperature=0.1, verbose=True)\n","llm_image = ChatOllama(model=\"llava:13b\", temperature=0.1, verbose=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mQ2tki_wB0cc"},"outputs":[],"source":["# ConversationalRetrievalChain 초기화 함수\n","def initialize_qa_chain(custom_db=None):\n","    \"\"\"\n","    QA 체인을 초기화하는 함수\n","    custom_db가 제공되면 해당 DB를 사용, 아니면 기본 DB 사용\n","    \"\"\"\n","    # 사용할 DB 결정\n","    if custom_db is None:\n","        db, _ = initialize_db()\n","    else:\n","        db = custom_db\n","\n","    # QA 체인 생성 및 반환\n","    return ConversationalRetrievalChain.from_llm(\n","        llm,\n","        db.as_retriever(search_kwargs={\"k\": 3}),\n","        return_source_documents=True,\n","        verbose=True,\n","        combine_docs_chain_kwargs={\"prompt\": PROMPT},\n","        memory=memory  # 기존 메모리 사용\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8rx48Je_B0cc"},"outputs":[],"source":["# 이미지 처리 함수\n","def process_image(image):\n","    if image is None:\n","        return None\n","\n","    try:\n","        buffered = BytesIO()\n","        image.save(buffered, format=\"JPEG\")\n","        img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n","        return f\"data:image/jpeg;base64,{img_str}\"\n","    except Exception as e:\n","        print(f\"이미지 처리 중 오류 발생: {str(e)}\")\n","        return None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oh6YEDNYB0cc"},"outputs":[],"source":["def generate_wordcloud():\n","    try:\n","        with open(MAIN_DOC_PATH, 'r', encoding='utf-8') as f:\n","            text = f.read()\n","\n","        wordcloud = WordCloud(\n","            font_path=FONT_PATH,\n","            background_color='white',\n","            width=800, height=400\n","        ).generate(text)\n","\n","        os.makedirs(os.path.dirname(IMG_PATH), exist_ok=True)\n","        plt.figure(figsize=(10, 5))\n","        plt.imshow(wordcloud, interpolation='bilinear')\n","        plt.axis('off')\n","        plt.savefig(IMG_PATH)\n","        plt.close()\n","\n","        return IMG_PATH\n","    except Exception as e:\n","        return f\"오류 발생: {e}\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fn7ljxCNB0cc"},"outputs":[],"source":["qa_chain = initialize_qa_chain()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Df0DCDHpB0cc"},"outputs":[],"source":["def chat(message, history, image=None):\n","    try:\n","        chat_history = [(human, ai) for human, ai in history]\n","        answer = \"\"\n","\n","        # 이미지 처리 부분\n","        if image is not None:\n","            processed_image = process_image(image)\n","            if processed_image:\n","                messages = [\n","                    HumanMessage(\n","                        content=[\n","                            {\"type\": \"text\", \"text\": message},\n","                            {\"type\": \"image_url\", \"image_url\": processed_image}\n","                        ]\n","                    )\n","                ]\n","\n","                try:\n","                    response = llm_image.invoke(messages)\n","                    image_answer = response.content\n","                    answer = f\"이미지 분석 결과: {image_answer}\"\n","                except Exception as img_error:\n","                    print(f\"이미지 분석 중 오류 발생: {str(img_error)}\")\n","                    answer = f\"이미지 분석 중 오류가 발생했습니다: {str(img_error)}\"\n","\n","        # 이미지가 없는 경우에만 텍스트 기반 응답 처리\n","        if not image:\n","            # 메인 문서만 사용하는 QA 체인 사용\n","            main_db, _ = initialize_db(use_main_only=True)\n","            main_qa_chain = initialize_qa_chain(main_db)\n","\n","            text_response = main_qa_chain({\"question\": message, \"chat_history\": chat_history})\n","            text_answer = text_response['answer']\n","\n","            # 참고 출처 정보 추가 (파일명만 표시)\n","            if 'source_documents' in text_response:\n","                sources = set([os.path.basename(doc.metadata.get('source', 'Unknown'))\n","                             for doc in text_response['source_documents']])\n","                source_info = f\"\\n\\n참고 파일: {', '.join(sources)}\" if sources else \"\"\n","                text_answer += source_info\n","\n","            answer = text_answer if not answer else f\"{answer}\\n\\n텍스트 응답: {text_answer}\"\n","\n","        chat_history.append((message, answer))\n","        return \"\", chat_history, None\n","\n","    except Exception as e:\n","        print(f\"채팅 함수 실행 중 오류 발생: {str(e)}\")\n","        error_message = f\"죄송합니다. 오류가 발생했습니다: {str(e)}\"\n","        chat_history.append((message, error_message))\n","        return \"\", chat_history, None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_0oq5i71B0cc"},"outputs":[],"source":["# 새로운 정보 추가 함수 (Gradio 인터페이스용)\n","def add_info(new_info):\n","    if not new_info.strip():\n","        return \"내용을 입력해주세요.\", new_info\n","    if add_new_information(new_info):\n","        return \"새로운 정보가 추가되었습니다. '전체 내용 보기' 버튼을 클릭하여 업데이트된 내용을 확인할 수 있습니다.\", \"\"\n","    else:\n","        return \"정보 추가에 실패했습니다. 다시 시도해 주세요.\", new_info"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X1sXYdyqB0cd"},"outputs":[],"source":["# temp 폴더 내 파일 목록을 불러오는 함수\n","def list_temp_files():\n","    if not os.path.exists(TEMP_FOLDER):\n","        os.makedirs(TEMP_FOLDER)\n","    return [os.path.basename(f) for f in glob.glob(os.path.join(TEMP_FOLDER, \"*.txt\"))]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iPlE9EPUB0cd"},"outputs":[],"source":["# 선택된 파일로부터 질의를 처리하는 함수\n","def ask_from_selected_file(selected_file, question):\n","    if not selected_file:\n","        return \"먼저 파일을 선택해주세요.\"\n","    if not question.strip():\n","        return \"질문을 입력해주세요.\"\n","\n","    try:\n","        file_path = os.path.join(TEMP_FOLDER, selected_file)\n","        if not os.path.exists(file_path):\n","            return f\"선택된 파일을 찾을 수 없습니다: {selected_file}\"\n","\n","        # 선택된 파일만으로 DB 초기화\n","        custom_db, custom_embeddings = initialize_db(file_path, use_main_only=False)\n","\n","        # 임시 QA 체인 생성\n","        temp_qa_chain = ConversationalRetrievalChain.from_llm(\n","            llm,\n","            custom_db.as_retriever(search_kwargs={\"k\": 3}),\n","            return_source_documents=True,\n","            verbose=True,\n","            combine_docs_chain_kwargs={\"prompt\": PROMPT},\n","            memory=ConversationBufferMemory(\n","                memory_key=\"chat_history\",\n","                output_key=\"answer\",\n","                return_messages=True\n","            )\n","        )\n","\n","        # 질문 처리\n","        response = temp_qa_chain({\"question\": question, \"chat_history\": []})\n","\n","        # 출처 정보 추가 (파일명만 표시)\n","        answer = response[\"answer\"]\n","        if 'source_documents' in response:\n","            sources = set([os.path.basename(doc.metadata.get('source', 'Unknown'))\n","                         for doc in response['source_documents']])\n","            source_info = f\"\\n\\n참고 파일: {', '.join(sources)}\" if sources else \"\"\n","            answer += source_info\n","\n","        return answer\n","\n","    except Exception as e:\n","        return f\"오류가 발생했습니다: {str(e)}\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C__woi1SB0cd"},"outputs":[],"source":["# Gradio 인터페이스 설정\n","with gr.Blocks(theme=gr.themes.Soft(), css=\"footer {display: none !important}\") as iface:\n","    gr.Markdown(\"# 휴먼먼(주) 정보 제공 AI 챗봇\")\n","\n","    with gr.Tabs():\n","        with gr.TabItem(\"채팅\"):\n","            chatbot = gr.Chatbot(height=600)\n","            msg = gr.Textbox(label=\"질문을 입력하세요\", lines=1)\n","            image_input = gr.Image(type=\"pil\", label=\"이미지 업로드 (선택사항)\")\n","\n","            with gr.Row():\n","                submit_btn = gr.Button(\"전송\", variant=\"primary\")\n","                clear_btn = gr.Button(\"대화 내용 지우기\")\n","\n","            gr.Examples(\n","                examples=[\n","                    [\"휴먼의 주소는 어디인가요?\", None],\n","                    [\"휴먼이 보유한 솔루션은 무엇인가요?\", None],\n","                    [\"휴먼의 영업대표는 누구인가요?\", None]\n","                ],\n","                inputs=[msg, image_input]\n","            )\n","\n","            msg.submit(chat, [msg, chatbot, image_input], [msg, chatbot, image_input])\n","            submit_btn.click(chat, [msg, chatbot, image_input], [msg, chatbot, image_input])\n","            clear_btn.click(lambda: (None, None), None, [chatbot, image_input])\n","\n","        with gr.TabItem(\"정보 추가\"):\n","            new_info_input = gr.Textbox(label=\"새로운 정보 추가\", lines=3)\n","            add_info_btn = gr.Button(\"정보 추가하기\")\n","            info_status = gr.Textbox(label=\"상태 메시지\", interactive=False)\n","\n","            add_info_btn.click(add_new_information, [new_info_input], [info_status])\n","\n","        with gr.TabItem(\"파일 관리\"):\n","            gr.Markdown(\"## temp 폴더에 파일 추가 및 질문\")\n","\n","            file_input = gr.File(label=\"Windows에서 파일 추가\")\n","            add_file_btn = gr.Button(\"파일 추가하기\")\n","            file_status = gr.Textbox(label=\"상태 메시지\", interactive=False)\n","\n","            file_list = gr.Dropdown(\n","                label=\"temp 폴더의 파일 선택\",\n","                choices=list_temp_files(),\n","                multiselect=False,\n","                interactive=True\n","            )\n","\n","            def update_file_list(file):\n","                status_message, _ = add_new_file(file)\n","                updated_files = list_temp_files()\n","                return status_message, gr.update(choices=updated_files)\n","\n","            add_file_btn.click(\n","                update_file_list,\n","                inputs=[file_input],\n","                outputs=[file_status, file_list]\n","            )\n","\n","            question_input = gr.Textbox(label=\"질문 입력\", lines=2, placeholder=\"질문을 입력하세요.\")\n","            submit_btn = gr.Button(\"질문 전송\", variant=\"primary\")\n","            answer_box = gr.Textbox(label=\"답변\", interactive=False)\n","\n","            submit_btn.click(\n","                ask_from_selected_file,\n","                inputs=[file_list, question_input],\n","                outputs=answer_box\n","            )\n","\n","        with gr.TabItem(\"전체 내용 보기\"):\n","            view_content_btn = gr.Button(\"전체 내용 보기\")\n","            content_display = gr.Textbox(label=\"전체 내용\", lines=10)\n","\n","            view_content_btn.click(view_all_content, None, content_display)\n","\n","        with gr.TabItem(\"단어시각화\"):\n","            generate_btn = gr.Button(\"Word Cloud 생성\")\n","            output_image = gr.Image()\n","            generate_btn.click(lambda: generate_wordcloud(), None, output_image)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eBSrMrEgB0ce"},"outputs":[],"source":["iface.launch(server_port=7861, server_name=\"0.0.0.0\")"]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}