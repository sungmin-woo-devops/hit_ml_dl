{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNEs2VNVBg2kddb/nIbCQtQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 챗봇 예제(역할 부여)"],"metadata":{"id":"8rzQMJLOpZx-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"NsBvwRX8pO_h"},"outputs":[],"source":["# 사전 설치 : pip install ollama\n","import ollama"]},{"cell_type":"code","source":["# 챗봇의 기본적 질문, 답변 역할\n","def ask_gemma(question):\n","    # ollama를 사용하여 모델로부터 응답 생성\n","    chatbot_role = \"너는 전문 심리 상담가야. 질문에 대한 답은 3줄 이내로 짧게해줘.\"\n","    response = ollama.chat(model='gemma2', messages=[\n","        {\"role\": \"system\", \"content\": chatbot_role},  # 챗봇의 기본 역할 부여\n","        {\"role\": \"user\", \"content\": question}, # 질문\n","    ])\n","\n","    return response['message']['content']"],"metadata":{"id":"dPGqP-0mpgmF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"행복하기 위해 어떻게 하면 좋을까?\"\n","response = ask_gemma(question)\n","print(response)"],"metadata":{"id":"ReMa2JuJpitO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DV_ws7zMpkPN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","## 챗봇 예제(Gradio 사용)"],"metadata":{"id":"R-cxqIfq5t-w"}},{"cell_type":"code","source":["# 사전 설치 : pip install gradio\n","from langchain_community.chat_models import ChatOllama\n","from langchain.schema import HumanMessage, AIMessage   # HumanMessage: 사용자가 보낸 메시지, AIMessage : LLM의 메시지\n","import gradio as gr"],"metadata":{"id":"rbN6safQ5w-s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ChatOllama 모델 초기화\n","model = ChatOllama(model=\"gemma2\", temperature=0.7, verbose=False)    # temperture가 낮을수록 거의 동일답변, 높을수록 창의적인 답변"],"metadata":{"id":"jY0UmlOE50Hk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 채팅 기록을 포함하여 응답을 생성하는 함수\n","def chat(message, history):\n","    # 이전 대화 기록을 ChatOllama 형식으로 변환\n","    chat_history = []\n","    for human, ai in history:\n","        chat_history.append(HumanMessage(content=human))\n","        chat_history.append(AIMessage(content=ai))\n","\n","    # 현재 메시지 추가\n","    chat_history.append(HumanMessage(content=message))\n","\n","    # 모델을 사용하여 응답 생성\n","    response = model.invoke(chat_history)\n","\n","    return response.content"],"metadata":{"id":"2zJaYFBo5507"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gradio 인터페이스 설정\n","demo = gr.ChatInterface(\n","    fn=chat,\n","    examples=[\n","        \"안녕하세요!\",\n","        \"인공지능에 대해 설명해주세요.\",\n","        \"파이썬의 장점은 무엇인가요?\"\n","    ],\n","    title=\"AI 챗봇\",\n","    description=\"질문을 입력하면 AI가 답변합니다.\"\n",")"],"metadata":{"id":"SdG5wA2g559M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 서버 실행\n","demo.launch(server_port=7861, server_name=\"0.0.0.0\")"],"metadata":{"id":"K61bFH905-v8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["demo.close()"],"metadata":{"id":"cQnckD8r6BC-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 챗봇 예제(Gradio + csv 사용)"],"metadata":{"id":"FCf5JjnI7Zpo"}},{"cell_type":"code","source":["import pandas as pd\n","from langchain_community.chat_models import ChatOllama\n","from langchain.schema import HumanMessage, AIMessage   # HumanMessage: 사용자가 보낸 메시지, AIMessage : LLM의 메시지\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.vectorstores import FAISS\n","from langchain.text_splitter import CharacterTextSplitter  # 특정 문자(예: 줄바꿈, 공백)를 기준으로 텍스트를 분할하는 기능을 제공\n","from langchain.chains import ConversationalRetrievalChain  # 질문과 관련된 정보 검색, 이전 대화정보도 같이 LLM에 제공, 답변생성\n","import gradio as gr"],"metadata":{"id":"3oLSrKNtCzzJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CSV 파일 로드\n","df = pd.read_csv(\"./dataset/indata_kor.csv\", encoding='CP949')"],"metadata":{"id":"bKpeX2zUDBX6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 텍스트 분할\n","text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200) # 텍스트 조각 최대 1000자, 텍스트 조각 사이에 200자만큼의 중복을 허용(문맥 유지)\n","texts = text_splitter.split_text(\"\\n\".join(df.to_string()))   # 문자열들을 줄바꿈 문자(\\n)를 기준으로 연결"],"metadata":{"id":"v5u024T1DQLq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 임베딩 모델 초기화\n","# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/distiluse-base-multilingual-cased-v2\")\n","# 모델 이름 : 조직이름(sentence-transformers) 다양한 작업 가능(all)-MS사 경령화 트랜스포머모델(MiniLM)-모델의 레이어수(L6)-모델이 버전(v2)\n","embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"],"metadata":{"id":"BLBU5vvtDbND"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 벡터 데이터베이스 생성\n","vectorstore = FAISS.from_texts(texts, embeddings)  # from_texts : 임베딩으로 변환된 벡터를 FAISS 인덱스에 저장"],"metadata":{"id":"KjdIcm9BDdh6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ChatOllama 모델 초기화\n","llm = ChatOllama(model=\"gemma2\", tempeature=0.1)   # temperture가 낮을수록 거의 동일답변, 높을수록 창의적인 답변"],"metadata":{"id":"yqqXwJ_mDfaY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["qa_chain = ConversationalRetrievalChain.from_llm(\n","    llm,\n","    vectorstore.as_retriever(search_kwargs={\"k\":1}),  # 가장 관련성 높은 1개의 문서만 검색\n","    return_source_documents=True,   # 참고한 소스 문서 정보 반환 여부\n","    verbose=False   # 체인의 실행 과정 출력 여부\n",")"],"metadata":{"id":"YB0eyNjRDhP8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 채팅 함수 정의\n","def chat(message, history):\n","    # 이전 대화 기록을 ConversationalRetrievalChain 형식으로 변환\n","    chat_history = [(human, ai) for human, ai in history]\n","\n","    # 모델을 사용하여 응답 생성\n","    response = qa_chain({\"question\": message, \"chat_history\": chat_history})\n","\n","    # 소스 문서 정보 추출\n","    sources = set([doc.metadata.get('source', 'Unknown') for doc in response['source_documents']])\n","    source_info = f\"\\n\\n참고 출처: {', '.join(sources)}\" if sources else \"\"\n","\n","    return response['answer'] + source_info"],"metadata":{"id":"eCz9P2IxDi6j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gradio 인터페이스 설정\n","demo = gr.ChatInterface(\n","    fn=chat,\n","    examples=[\n","        \"한국폴리텍대학 스마트금융과 면접시에는 어떤걸 준비하고 가면 될까요?\",\n","        \"스마트금융과에 대해 설명해주세요\",\n","        \"한국폴리텍대한 추천할만한 학과 하나를 소개해주세요.\"\n","    ],\n","    title=\"대학 정보 AI 챗봇\",\n","    description=\"스마트금융과에 대한 질문을 입력하면 AI가 CSV데이터를 참고하여 한글로 답변합니다.\"\n",")"],"metadata":{"id":"tm2rFQZQDl4i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 서버 실행\n","demo.launch(server_port=7861, server_name=\"0.0.0.0\")"],"metadata":{"id":"T4xwawRwDn6i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["demo.close()"],"metadata":{"id":"hbb6ddi9Dp7W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 챗봇 예제(인터넷 URL정보 요약하기 + TAB추가)"],"metadata":{"id":"vK0ojsUOkVJp"}},{"cell_type":"code","source":["import gradio as gr\n","import bs4\n","from langchain.text_splitter import RecursiveCharacterTextSplitter  # 텍스트를 분할하는 기준 제공\n","from langchain_community.document_loaders import WebBaseLoader    # 웹페이지의 콘텐츠를 불러오는(로드하는) 기능을 제공\n","from langchain.vectorstores import FAISS\n","from langchain_community.embeddings import OllamaEmbeddings\n","import ollama"],"metadata":{"id":"lSjkK57ZkjnH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 텍스트 콘텐츠를 추출하여, 줄바꿈(\\n\\n)으로 구분된 단일 문자열로 결합\n","\n","def load_and_retrieve_docs(url):\n","    loader = WebBaseLoader(\n","        web_paths=(url,),\n","        bs_kwargs=dict()\n","    )\n","\n","    docs = loader.load()\n","    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n","    splits = text_splitter.split_documents(docs)\n","    embeddings = OllamaEmbeddings(model=\"gemma2\")\n","\n","    # vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n","    vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n","\n","    return vectorstore.as_retriever()"],"metadata":{"id":"mk-yU2C_k8ll"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to format documents\n","\n","def format_docs(docs):\n","\n","    return \"\\n\\n\".join(doc.page_content for doc in docs)"],"metadata":{"id":"RwFh2kyylJWe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# RAG 시스템을 구현하여 주어진 URL의 웹페이지 콘텐츠를 기반으로 사용자의 질문에 답변을 생성하는 역할\n","\n","def rag_chain(url, question):\n","\n","    retriever = load_and_retrieve_docs(url)\n","\n","    retrieved_docs = retriever.invoke(question)\n","\n","    formatted_context = format_docs(retrieved_docs)\n","\n","    formatted_prompt = f\"Question: {question}\\n\\nContext: {formatted_context}\"\n","\n","    response = ollama.chat(model='gemma2', messages=[{'role': 'user', 'content': formatted_prompt}])\n","\n","    return response['message']['content']"],"metadata":{"id":"BLOOifhilUTQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gradio interface\n","\n","# iface = gr.Interface(\n","\n","#     fn=rag_chain,\n","\n","#     inputs=[\"text\", \"text\"],\n","\n","#     outputs=\"text\",\n","\n","#     title=\"RAG Chain Question Answering\",\n","\n","#     description=\"Enter a URL and a query to get answers from the RAG chain.\"\n","\n","# )"],"metadata":{"id":"4zXQPQ9slXRZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gradio Tabbed Interface\n","with gr.Blocks() as iface:\n","    # Tab for Question and Answer\n","    with gr.Tab(\"질문과 답변\"):\n","        gr.Interface(\n","            fn=rag_chain,\n","            inputs=[\"text\", \"text\"],\n","            outputs=\"text\",\n","            title=\"RAG Chain Question Answering\",\n","            description=\"URL과 질문을 입력하면 RAG 체인에서 답변을 받으실 수 있습니다.\"\n","        )\n","\n","    # Tab for Visualization (Word Cloud)\n","    with gr.Tab(\"시각화 (워드클라우드)\"):\n","        gr.Markdown(\"이 탭은 시각화를 위한 공간입니다. 워드클라우드 기능이 여기에 추가될 예정입니다.\")"],"metadata":{"id":"dctFYlodZ8pA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 디버그 모드로 Gradio 인터페이스 실행\n","iface.launch(server_port=7861, server_name=\"0.0.0.0\", debug=True)"],"metadata":{"id":"3tGD0r5llZo6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iface.close()"],"metadata":{"id":"WA-01KB5leYw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 챗봇 예제(STT:음성을 텍스트로 전환)"],"metadata":{"id":"g9ospsRFMNEa"}},{"cell_type":"code","source":["# 사전 설치 : pip install openai-whisper\n","# ffmpeg 사전 설치 및 환경변수 path 설정(경로/bin)\n","# 코랩 audio에서 테스트할 샘플 오디오 파일 다운\n","import os\n","from dotenv import load_dotenv  # 환경변수 로드가 필요한 경우\n","import whisper\n","import gradio as gr"],"metadata":{"id":"mYWM66giMS3E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# .env 파일에서 환경 변수 로드 (필요한 경우)\n","# load_dotenv()"],"metadata":{"id":"WY1udsUiMZu3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ffmpeg 경로 명시적 설정\n","# os.environ[\"FFMPEG_BINARY\"] = \"C:/aiproject/ffmpeg/bin/ffmpeg.exe\"\n","os.environ[\"PATH\"] += os.pathsep + r\"C:\\aiproject\\ffmpeg\\bin\"\n","os.environ[\"FFMPEG_BINARY\"] = r\"C:\\aiproject\\ffmpeg\\bin\\ffmpeg.exe\""],"metadata":{"id":"d3ycBKMcMcaD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def transcribe_audio(audio_path):\n","    # Whisper 모델 로드\n","    model = whisper.load_model(\"base\")\n","\n","    # 오디오 파일 전사\n","    result = model.transcribe(audio_path)\n","\n","    # 전사된 텍스트 반환\n","    return result[\"text\"]"],"metadata":{"id":"O2zezOlzMfQM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_audio(audio):\n","    if audio is None:\n","        return \"오디오 파일을 업로드해주세요.\"\n","    try:\n","        transcribed_text = transcribe_audio(audio)\n","        return transcribed_text\n","    except Exception as e:\n","        return f\"오류가 발생했습니다: {str(e)}\""],"metadata":{"id":"JItDUD4tMjuB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gradio 인터페이스 생성\n","iface = gr.Interface(\n","    fn=process_audio,\n","    inputs=gr.Audio(type=\"filepath\", label=\"MP3 파일 업로드\"),\n","    outputs=\"text\",\n","    title = \"MP3 to Text Converter\",\n","    description=\"MP3 파일을 업로드하면 텍스트로 변환합니다.\"\n",")"],"metadata":{"id":"bXMJYerdMkXc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 디버그 모드로 Gradio 인터페이스 실행\n","iface.launch(server_port=7861, server_name=\"0.0.0.0\", debug=True)"],"metadata":{"id":"cG0S00WNMmx1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iface.close()"],"metadata":{"id":"c_sgIi9qMt6W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 챗봇 예제(TTS:텍스트를 음성변환)"],"metadata":{"id":"DM7GECJ_qeXi"}},{"cell_type":"code","source":["# 사전 설치 : pip install gtts\n","import gradio as gr\n","from gtts import gTTS\n","import os\n","import tempfile"],"metadata":{"id":"dpNqBrqyqjOu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def text_to_speech(text, lang='ko'):\n","    # 임시 파일 생성\n","    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as fp:\n","        temp_filename = fp.name\n","\n","    # TTS 변환\n","    tts = gTTS(text=text, lang=lang)\n","    tts.save(temp_filename)\n","    return temp_filename"],"metadata":{"id":"bH51Lycdqsqr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_tts(text, lang):\n","    if not text:\n","        return None, \"텍스트를 입력해주세요.\"\n","    try:\n","        audio_file = text_to_speech(text, lang)\n","        return audio_file, \"변환이 완료되었습니다. 아래에서 재생 또는 다운로드할 수 있습니다.\"\n","    except Exception as e:\n","        return None, f\"오류가 발생했습니다: {str(e)}\""],"metadata":{"id":"9qWFYZUrq0Ow"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gradion 인터페이스 생성\n","iface = gr.Interface(\n","    fn=process_tts,\n","    inputs=[\n","        gr.Textbox(lines=5, label=\"텍스트 입력\"),\n","        gr.Dropdown(choices=['ko', 'en', 'ja', 'zh-cn'], label=\"언어 선택\", value='ko')\n","    ],\n","    outputs=[\n","        gr.Audio(label=\"생성된 오디오\"),\n","        gr.Textbox(label=\"상태 메시지\")\n","    ],\n","    title = \"Text to Speech Converter\",\n","    description=\"텍스트를 입력하연 MP3 파일로 변환합니다.\"\n",")"],"metadata":{"id":"7MCaEAceq0Rq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 디버그 모드로 Gradio 인터페이스 실행\n","iface.launch(server_port=7861, server_name=\"0.0.0.0\", debug=True)"],"metadata":{"id":"QQcdT_rfq7Ih"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iface.close()"],"metadata":{"id":"pj21cvAtq9mF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 이미지 분류 예제(Gradio 사용)"],"metadata":{"id":"sJRqmmWSgg8P"}},{"cell_type":"code","source":["# 사전설치 : pip install pillow\n","import gradio as gr\n","import tensorflow as tf\n","import numpy as np\n","from PIL import Image\n","import requests  # URL에서 데이터를 가져오기 위해 HTTP 요청을 보내는 라이브러리\n","from io import BytesIO #  메모리에서 바이트 데이터를 저장하고 읽는 기능"],"metadata":{"id":"VQ2yE85fhF_9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TensorFlow MobileNetV2 모델 로드\n","model = tf.keras.applications.MobileNetV2(weights=\"imagenet\")  # 사전 훈련된 ImageNet 가중치를 사용"],"metadata":{"id":"0HBSfBMRhH_P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_image(image_url):\n","    try:\n","        # URL에서 이미지 가져오기\n","        response = requests.get(image_url)\n","        image = Image.open(BytesIO(response.content)).resize((224, 224))  # BytesIO 사용하여 이미지 열기\n","\n","        # 이미지를 배열로 변환\n","        image_array = tf.keras.preprocessing.image.img_to_array(image) # 이미지를 숫자 배열로 전환\n","        image_array = tf.expand_dims(image_array, axis=0)  # 모델이 한 번에 여러 이미지를 처리할 수 있게 \"배치\"라는 차원을 추가\n","        image_array = tf.keras.applications.mobilenet_v2.preprocess_input(image_array)  # 이미지 픽셀 값을 모델이 학습할 때 사용했던 범위로 조정 스케일링\n","\n","        # 예측 수행\n","        predictions = model.predict(image_array)  # 이미지를 분류하여 1000개 클래스에 대한 확률을 출력\n","        decoded_predictions = tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=3)[0]  # 상위 3개 예측 결과 반환\n","\n","        # Gradio Label 컴포넌트에 맞게 결과 형식 변경\n","        # 예: {\"pizza\": 0.95, \"burger\": 0.03, \"salad\": 0.02} 형식으로 반환\n","        result = {label: float(prob) for (_, label, prob) in decoded_predictions}\n","        return result\n","\n","    except Exception as e:\n","        return {\"error\": 1.0}  # 에러 발생 시 기본값 반환"],"metadata":{"id":"Um-ApCWohKDd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gradio 인터페이스 생성\n","iface = gr.Interface(\n","    fn=predict_image,\n","    inputs=gr.Textbox(label=\"이미지 URL 입력\"),\n","    outputs=gr.Label(num_top_classes=3, label=\"예측 결과\"),\n","    title=\"음식 이미지 분류\",\n","    description=\"이미지 URL을 입력하면 상위 3개의 예측 결과를 확률과 함께 표시합니다.\"\n",")"],"metadata":{"id":"a98LEX8HhMtu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 인터페이스 실행\n","iface.launch(server_port=7861, server_name=\"0.0.0.0\", debug=True)\n","\n","# 예시 이미지 URL : https://health.chosun.com/site/data/img_dir/2024/04/19/2024041901914_0.jpg"],"metadata":{"id":"PJzF5Uo0hRZt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iface.close()"],"metadata":{"id":"VHviyxIwhTIV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 이미지 분류 예제(Gradio + gemma2 사용)"],"metadata":{"id":"cwINN5mgkLxs"}},{"cell_type":"code","source":["import gradio as gr\n","import tensorflow as tf\n","import numpy as np\n","from PIL import Image\n","import requests\n","from io import BytesIO\n","from langchain_community.chat_models import ChatOllama"],"metadata":{"id":"LjUBMu9_kOty"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TensorFlow MobileNetV2 모델 로드\n","model = tf.keras.applications.MobileNetV2(weights=\"imagenet\")  # 사전 훈련된 가중치를 사용"],"metadata":{"id":"bALnjk8ykadz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["OLLAMA_SERVER = \"http://localhost:11434\"  # 로컬 서버 주소\n","MODEL_NAME = \"gemma2\"  # 사용하려는 Ollama 모델 이름"],"metadata":{"id":"LT1CL6Z1kb-J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ollama를 사용해 음식 설명 생성\n","def get_food_description_with_langchain(food_name):\n","    \"\"\"\n","    LangChain ChatOllama를 사용하여 음식 설명 생성\n","    \"\"\"\n","    try:\n","        chat = ChatOllama(base_url=OLLAMA_SERVER, model=MODEL_NAME)\n","        prompt = f\"{food_name}에 대해 특징, 효능, 요리 레시피 설명해줘.설명은 한국어로 해줘.\"\n","        response = chat.predict(prompt)\n","        return response\n","    except Exception as e:\n","        return f\"Failed to retrieve description: {e}\""],"metadata":{"id":"WC-uRfbckdnZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이미지 예측 함수\n","def predict_image_with_description(image_url):\n","    \"\"\"\n","    이미지 URL을 받아 음식 예측과 Ollama 설명을 반환\n","    \"\"\"\n","    try:\n","        # URL에서 이미지 가져오기\n","        response = requests.get(image_url)\n","        image = Image.open(BytesIO(response.content)).resize((224, 224))  # BytesIO 사용하여 이미지 열기\n","\n","        # 이미지를 배열로 변환\n","        image_array = tf.keras.preprocessing.image.img_to_array(image)  # 이미지를 숫자 배열로 전환\n","        image_array = tf.expand_dims(image_array, axis=0)  # 모델이 한 번에 여러 이미지를 처리할 수 있게 \"배치\"라는 차원을 추가\n","        image_array = tf.keras.applications.mobilenet_v2.preprocess_input(image_array)  # 이미지 픽셀 값을 모델이 학습할 때 사용했던 범위로 조정 전처리\n","\n","        # 예측 수행\n","        predictions = model.predict(image_array)\n","        decoded_predictions = tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=3)[0]  # 상위 3개 예측 결과 반환\n","\n","        # 예측 결과 형식화\n","        result = {label: float(prob) for (_, label, prob) in decoded_predictions} # 예측 결과를 Gradio의 Label 컴포넌트가 요구하는 형식으로 변환\n","\n","        # 가장 높은 확률의 예측값으로 Ollama 설명 생성\n","        top_food = decoded_predictions[0][1]  # 가장 확률이 높은 음식 이름\n","        description = get_food_description_with_langchain(top_food)\n","\n","        return result, description  # 예측 결과와 Ollama 설명 반환\n","\n","    except Exception as e:\n","        return {\"error\": 1.0}, f\"Error: {e}\"  # 에러 발생 시 기본값 반환"],"metadata":{"id":"txY9j-odkfW2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gradio 인터페이스 생성\n","iface = gr.Interface(\n","    fn=predict_image_with_description,\n","    inputs=gr.Textbox(label=\"이미지 URL 입력\"),\n","    outputs=[\n","        gr.Label(num_top_classes=3, label=\"예측 결과\"),  # 상위 3개 예측 결과\n","        gr.Textbox(label=\"음식 설명\", interactive=False)  # Ollama로 생성한 설명 출력\n","    ],\n","    title=\"음식 이미지 분류 및 설명 생성기\",\n","    description=\"이미지 URL을 입력하면 음식 분류 결과와 설명을 제공합니다.\"\n",")"],"metadata":{"id":"a_DgwmXskhEA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 인터페이스 실행\n","iface.launch(server_port=7861, server_name=\"0.0.0.0\", debug=True)"],"metadata":{"id":"B-uWIiYJkjhk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iface.close()"],"metadata":{"id":"fQu5BogaklO7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## DB접속 챗봇 예제(Gradio 사용)"],"metadata":{"id":"QiFQGWRy-Szk"}},{"cell_type":"code","source":["import gradio as gr\n","import pandas as pd\n","from sqlalchemy import create_engine, text\n","from langchain.prompts import ChatPromptTemplate\n","from langchain.chains import LLMChain\n","from langchain.llms import Ollama\n","from langchain.callbacks.manager import CallbackManager # 다양한 이벤트에 대한 콜백을 관리하는 클래스\n","from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler  # 텍스트 생성되는 대로 바로 출력\n","import re  # 텍스트 패턴을 정의 (텍스트를 검색, 치환, 분리)\n","from typing import Dict, Any  # 타입을 명시적으로 지정하여 코드의 가독성과 안정성을 높임\n","import json"],"metadata":{"id":"DB88ZtPP-PTt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# DB 연결 설정\n","DB_URL = \"mysql+pymysql://root:비밀번호@localhost:3306/test\"\n","engine = create_engine(DB_URL)"],"metadata":{"id":"P2zQLdq8-TzC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class EnhancedQueryGenerator:\n","    \"\"\"향상된 SQL 쿼리 생성 클래스\"\"\"\n","\n","    def __init__(self):\n","        self.query_template = \"\"\"\n","        당신은 한국어를 잘하고 MySQL 데이터베이스의 쿼리를 생성하는 전문가입니다.\n","        데이터베이스 스키마 정보:\n","        {schema_info}\n","\n","        이전 피드백 정보:\n","        {feedback_info}\n","\n","        위 정보를 바탕으로 다음 질문에 대한 MySQL 쿼리를 생성해주세요.\n","        질문: {question}\n","\n","        규칙:\n","        1. 순수한 SQL 쿼리만 작성하세요\n","        2. 컬럼의 실제 값을 기준으로 쿼리를 작성하세요\n","        3. 설명이나 주석을 포함하지 마세요\n","        4. 쿼리는 SELECT 문으로 시작하고 세미콜론(;)으로 끝나야 합니다\n","        5. WHERE 절에서는 정확한 값 매칭을 위해 = 연산자를 사용하세요\n","        6. 유사 검색이 필요한 경우 LIKE '%키워드%' 를 사용하세요\n","        7. 관련된 모든 결과를 찾기 위해 적절히 OR 조건을 활용하세요\n","        \"\"\"\n","\n","        self.answer_template = \"\"\"\n","        다음 정보를 바탕으로 사용자의 질문에 대한 답변을 생성해주세요:\n","\n","        원래 질문: {question}\n","        실행된 쿼리: {query}\n","        쿼리 결과: {result}\n","\n","        규칙:\n","        1. 결과를 자연스러운 한국어로 설명해주세요\n","        2. 숫자 데이터가 있다면 적절한 단위와 함께 표현해주세요\n","        3. 결과가 없다면 그 이유를 설명해주세요\n","        4. 전문적인 용어는 쉽게 풀어서 설명해주세요\n","        \"\"\"\n","\n","        # Gemma2 모델 초기화\n","        callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n","        self.llm = Ollama(\n","            model=\"gemma2\",\n","            temperature=0,\n","            callback_manager=callback_manager\n","        )\n","\n","        # 프롬프트 템플릿 설정\n","        self.query_prompt = ChatPromptTemplate.from_template(self.query_template)\n","        self.answer_prompt = ChatPromptTemplate.from_template(self.answer_template)\n","\n","        # Chain 설정\n","        self.query_chain = LLMChain(llm=self.llm, prompt=self.query_prompt)\n","        self.answer_chain = LLMChain(llm=self.llm, prompt=self.answer_prompt)\n","\n","    def generate_query(self, question: str, schema_info: str, feedback_info: str = \"\") -> str:\n","        \"\"\"질문에 대한 SQL 쿼리를 생성합니다.\"\"\"\n","        response = self.query_chain.run(\n","            question=question,\n","            schema_info=schema_info,\n","            feedback_info=feedback_info\n","        )\n","        return self.extract_sql_query(response)\n","\n","    def generate_answer(self, question: str, query: str, result: Any) -> str:\n","        \"\"\"쿼리 결과를 바탕으로 자연어 답변을 생성합니다.\"\"\"\n","        result_str = str(result) if isinstance(result, pd.DataFrame) else json.dumps(result, ensure_ascii=False)\n","        response = self.answer_chain.run(\n","            question=question,\n","            query=query,\n","            result=result_str\n","        )\n","        return response.strip()\n","\n","    @staticmethod  # 메서드가 클래스의 인스턴스 없이도 호출\n","    def extract_sql_query(response: str) -> str:\n","        \"\"\"응답에서 SQL 쿼리를 추출합니다.\"\"\"\n","        response = response.replace('```sql', '').replace('```', '').strip()\n","        match = re.search(r'SELECT.*?;', response, re.DOTALL | re.IGNORECASE)\n","        return match.group(0).strip() if match else response.strip()\n","\n","# 쿼리 결과 반환\n","def get_schema_info():\n","    \"\"\"데이터베이스 스키마 정보를 가져옵니다.\"\"\"\n","    with engine.connect() as conn:\n","        tables = pd.read_sql(\"SHOW TABLES\", conn)\n","        schema_info = []\n","\n","        for table in tables.iloc[:, 0]:\n","            columns = pd.read_sql(f\"DESCRIBE {table}\", conn)\n","            schema_info.append(f\"테이블: {table}\")\n","            schema_info.append(\"컬럼:\")\n","            for _, row in columns.iterrows():\n","                schema_info.append(f\"- {row['Field']} ({row['Type']})\")\n","            schema_info.append(\"\")\n","\n","        return \"\\n\".join(schema_info)\n","\n","def execute_query(query):\n","    \"\"\"SQL 쿼리를 실행하고 결과를 반환합니다.\"\"\"\n","    try:\n","        with engine.connect() as conn:\n","            result = pd.read_sql(query, conn)\n","            return result\n","    except Exception as e:\n","        return f\"쿼리 실행 중 오류 발생: {str(e)}\"\n","\n","def process_question(question):\n","    \"\"\"질문을 처리하고 결과를 반환합니다.\"\"\"\n","    schema_info = get_schema_info()\n","    query_generator = EnhancedQueryGenerator()\n","\n","    # 쿼리 생성\n","    query = query_generator.generate_query(question, schema_info)\n","\n","    # 쿼리 실행\n","    result = execute_query(query)\n","\n","    # 답변 생성\n","    answer = query_generator.generate_answer(question, query, result)\n","\n","    return query, result, answer"],"metadata":{"id":"uCSNxjxO-YSV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gradio 인터페이스 생성\n","def create_interface():\n","    with gr.Blocks() as demo:\n","        gr.Markdown(\"# DB 문의 챗봇 (Gemma2 기반)\")\n","\n","        with gr.Row():\n","            question_input = gr.Textbox(\n","                label=\"질문을 입력하세요\",\n","                placeholder=\"데이터베이스에 대해 궁금한 점을 물어보세요...\"\n","            )\n","\n","        with gr.Row():\n","            submit_btn = gr.Button(\"질문하기\")\n","\n","        with gr.Row():\n","            query_output = gr.Textbox(label=\"생성된 SQL 쿼리\")\n","\n","        with gr.Row():\n","            with gr.Column():\n","                result_output = gr.Dataframe(label=\"쿼리 실행 결과\")\n","\n","        with gr.Row():\n","            answer_output = gr.Textbox(\n","                label=\"AI 답변\",\n","                lines=5\n","            )\n","\n","        submit_btn.click(\n","            fn=process_question,\n","            inputs=[question_input],\n","            outputs=[query_output, result_output, answer_output]\n","        )\n","\n","    return demo"],"metadata":{"id":"WFpsrEdf-ZyX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 인터페이스 실행\n","if __name__ == \"__main__\":\n","    demo = create_interface()\n","    demo.launch(server_port=7861, server_name=\"0.0.0.0\", debug=True)"],"metadata":{"id":"ThqIMqVF-bil"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["demo.close()"],"metadata":{"id":"qssZHX-P-dMB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 자기소개서 도우미 챗봇 예제(Gradio)"],"metadata":{"id":"oqNz5q537vmr"}},{"cell_type":"code","source":["# 사전 설치 : pip install fpdf\n","import os\n","import gradio as gr\n","from langchain.llms import Ollama\n","from langchain.chains import LLMChain, SimpleSequentialChain\n","from langchain.prompts import PromptTemplate\n","from fpdf import FPDF"],"metadata":{"id":"wFZVtgNA7584"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ollama 설정 (Gemma2 모델 사용)\n","os.environ[\"OLLAMA_API_BASE\"] = \"http://localhost:11434\"  # Ollama 서버 주소\n","ollama_model = Ollama(model=\"gemma2\")"],"metadata":{"id":"yG9m2sD_RFBI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 다양한 템플릿 설정\n","TEMPLATES = {\n","    \"취업\": \"다음 키워드와 예시를 바탕으로, 취업 지원을 위한 자기소개서를 작성하세요.\",\n","    \"대학원\": \"제공된 키워드를 사용하여, 대학원 지원을 위한 자기소개서를 초안 작성하세요.\",\n","    \"봉사활동\": \"주어진 키워드를 활용하여, 봉사활동 경험과 동기를 강조하는 자기소개서를 작성하세요.\"\n","}"],"metadata":{"id":"r1i7JWXM772s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 언어 지원: 한국어, 영어, 일본어\n","LANGUAGES = {\n","    \"한국어\": \"Please write the response in Korean.\",\n","    \"영어\": \"Please write the response in English.\",\n","    \"일본어\": \"Please write the response in Japanese.\"\n","}"],"metadata":{"id":"fZsRwUPo7-BD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 자동 키워드 추천 함수\n","def recommend_keywords(purpose):\n","    if purpose == \"취업\":\n","        return \"책임감, 팀워크, 문제 해결 능력\"\n","    elif purpose == \"대학원\":\n","        return \"연구 열정, 창의력, 학업 성취도\"\n","    elif purpose == \"봉사활동\":\n","        return \"사회적 책임감, 희생정신, 리더십\"\n","    else:\n","        return \"\""],"metadata":{"id":"E1w97Ked8AAK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 자기소개서 작성 함수\n","def generate_statement(purpose, language, keywords, example_sentence=None):\n","    if purpose not in TEMPLATES:\n","        return \"지원 목적을 올바르게 선택해주세요.\"\n","    if language not in LANGUAGES:\n","        return \"언어를 올바르게 선택해주세요.\"\n","\n","    # 템플릿 생성\n","    template = TEMPLATES[purpose] + \"\\n\\nKeywords: {keywords}\\n\" + LANGUAGES[language]\n","    if example_sentence:\n","        template += f\"\\n\\nExample sentence: {example_sentence}\"\n","\n","    prompt = PromptTemplate(input_variables=[\"keywords\"], template=template)\n","    chain = LLMChain(llm=ollama_model, prompt=prompt)\n","    response = chain.run({\"keywords\": keywords})\n","    return response"],"metadata":{"id":"Z6pNNRhw8CQ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PDF 저장 함수\n","def save_to_pdf(statement, filename=\"personal_statement.pdf\"):\n","    pdf = FPDF()\n","    pdf.add_page()  # pdf 문서에 새로운 페이지 추가\n","    pdf.add_font('MalgunGothic', '', r'C:\\Windows\\Fonts\\malgun.ttf', uni=True)  # '맑은 고딕' 폰트 경로 설정\n","    pdf.set_font('MalgunGothic', size=12)  # 폰트 설정\n","    pdf.multi_cell(0, 10, statement) # PDF 문서에 텍스트를 추가, 셀의너비(0), 셀의 높이(10)\n","    pdf.output(filename) # PDF 문서를 파일로 저장\n","    return f\"✔️ PDF 저장 완료: {filename}\""],"metadata":{"id":"AZE1faEU8D-L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gradio 인터페이스\n","def chatbot_interface(purpose, language, keywords, example_sentence=None, save_pdf=False):\n","    statement = generate_statement(purpose, language, keywords, example_sentence)\n","    if save_pdf:\n","        save_to_pdf(statement)\n","    return statement"],"metadata":{"id":"oTBUg-ThNzX3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with gr.Blocks() as demo:\n","    gr.Markdown(\"# 📝 다목적 자기소개서 작성 도우미\")\n","    gr.Markdown(\"키워드와 추천 문장을 활용하여 취업, 대학원, 봉사활동 자기소개서를 생성하고 PDF로 저장하세요!\")\n","\n","    # 입력 영역\n","    with gr.Row():\n","        purpose_input = gr.Dropdown(label=\"지원 목적\", choices=[\"취업\", \"대학원\", \"봉사활동\"], value=\"취업\")\n","        language_input = gr.Dropdown(label=\"언어 선택\", choices=[\"한국어\", \"영어\", \"일본어\"], value=\"한국어\")\n","\n","    recommended_keywords = gr.Textbox(label=\"추천 키워드\", interactive=False)\n","    recommend_btn = gr.Button(\"키워드 추천\")\n","    recommend_btn.click(recommend_keywords, inputs=[purpose_input], outputs=[recommended_keywords])\n","\n","    with gr.Row():\n","        keywords_input = gr.Textbox(label=\"사용자 키워드 입력\", placeholder=\"예: 책임감, 팀워크, 문제 해결 능력\")\n","        example_sentence_input = gr.Textbox(\n","            label=\"추천 문장 (선택 사항)\",\n","            placeholder=\"예: '저는 도전을 두려워하지 않고 성공적으로 프로젝트를 완수했습니다.'\"\n","        )\n","\n","    save_pdf_toggle = gr.Checkbox(label=\"PDF로 저장\", value=False)\n","\n","    # 출력 영역\n","    output = gr.Textbox(label=\"작성된 자기소개서\", lines=6)\n","    submit_btn = gr.Button(\"작성하기\")\n","    submit_btn.click(\n","        fn=chatbot_interface,\n","        inputs=[purpose_input, language_input, keywords_input, example_sentence_input, save_pdf_toggle],\n","        outputs=[output]\n","    )"],"metadata":{"id":"I5KDLrAF8GCR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 실행\n","demo.launch()"],"metadata":{"id":"ylQ7KooL8H_a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 종료(자원회수)\n","demo.close()"],"metadata":{"id":"jH9y726Q8J-8"},"execution_count":null,"outputs":[]}]}